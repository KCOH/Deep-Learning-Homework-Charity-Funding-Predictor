{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe0e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2058762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d30dfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop(labels=[\"EIN\", \"NAME\"], axis=1)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c66b400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket APPLICATION_TYPE\n",
    "application_counts = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "\n",
    "# Determine which values to replace if counts are less than 500\n",
    "replace_application = list(application_counts[application_counts < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    application_df[\"APPLICATION_TYPE\"] = application_df[\"APPLICATION_TYPE\"].replace(app, \"Other\")\n",
    "\n",
    "# Bucket CLASSIFICATION\n",
    "classification_counts = application_df[\"CLASSIFICATION\"].value_counts()\n",
    "\n",
    "# Determine which values to replace if counts are less than 1800\n",
    "replace_class = list(classification_counts[classification_counts < 1800].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df[\"CLASSIFICATION\"] = application_df[\"CLASSIFICATION\"].replace(cls, \"Other\")\n",
    "\n",
    "# Generate our categorical variable lists\n",
    "application_cat = list(application_df.dtypes[application_df.dtypes == \"object\"].index)\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "\n",
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df, left_index=True, right_index=True)\n",
    "application_df = application_df.drop(labels=application_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1667d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df[\"IS_SUCCESSFUL\"].values.reshape(-1, 1)\n",
    "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62aa1754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa8b31da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "# number of layer1 neurons = 2*(number of inputs=43) = 86 ~ 80\n",
    "hidden_nodes_layer1 = 80\n",
    "# number of layer2 neurons: Between (input=80) and (output=1 - classifier)\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn_inc_epochs = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f39ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 80)                3520      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,981\n",
      "Trainable params: 5,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First hidden layer\n",
    "nn_inc_epochs.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_inc_epochs.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_inc_epochs.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_inc_epochs.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff2a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_inc_epochs.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f51a1c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "804/804 [==============================] - 1s 965us/step - loss: 0.5325 - accuracy: 0.7400\n",
      "Epoch 2/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5322 - accuracy: 0.7406\n",
      "Epoch 3/200\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.7402 ETA: 0s - loss: 0.5346 - accuracy:  - 1s 992us/step - loss: 0.5328 - accuracy: 0.7400\n",
      "Epoch 4/200\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5327 - accuracy: 0.74010s - loss: 0.5504 - accura - ETA: 0s - loss: 0.5370 - accura - ETA: 0s - loss: 0.5358 - accuracy\n",
      "Epoch 5/200\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5320 - accuracy: 0.7406\n",
      "Epoch 6/200\n",
      "804/804 [==============================] - 1s 955us/step - loss: 0.5323 - accuracy: 0.7406\n",
      "Epoch 7/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5325 - accuracy: 0.7404\n",
      "Epoch 8/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5320 - accuracy: 0.7397\n",
      "Epoch 9/200\n",
      "804/804 [==============================] - 1s 953us/step - loss: 0.5321 - accuracy: 0.7404\n",
      "Epoch 10/200\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5325 - accuracy: 0.74000s - loss: 0.5326 - accu\n",
      "Epoch 11/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5324 - accuracy: 0.74000s - loss: 0.5303 - \n",
      "Epoch 12/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5350 - accuracy: 0.73970s - loss:\n",
      "Epoch 13/200\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5330 - accuracy: 0.7399\n",
      "Epoch 14/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5325 - accuracy: 0.7400\n",
      "Epoch 15/200\n",
      "804/804 [==============================] - 1s 969us/step - loss: 0.5330 - accuracy: 0.7406\n",
      "Epoch 16/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5320 - accuracy: 0.7408\n",
      "Epoch 17/200\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5320 - accuracy: 0.7406\n",
      "Epoch 18/200\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5319 - accuracy: 0.74070s - los\n",
      "Epoch 19/200\n",
      "804/804 [==============================] - 1s 960us/step - loss: 0.5324 - accuracy: 0.7403\n",
      "Epoch 20/200\n",
      "804/804 [==============================] - 1s 996us/step - loss: 0.5326 - accuracy: 0.7402\n",
      "Epoch 21/200\n",
      "804/804 [==============================] - 1s 975us/step - loss: 0.5329 - accuracy: 0.7394\n",
      "Epoch 22/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5321 - accuracy: 0.7406\n",
      "Epoch 23/200\n",
      "804/804 [==============================] - 1s 958us/step - loss: 0.5318 - accuracy: 0.7406\n",
      "Epoch 24/200\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5320 - accuracy: 0.7406\n",
      "Epoch 25/200\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5324 - accuracy: 0.7405\n",
      "Epoch 26/200\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5323 - accuracy: 0.74050s - loss: 0.5300 - accu\n",
      "Epoch 27/200\n",
      "804/804 [==============================] - 1s 958us/step - loss: 0.5321 - accuracy: 0.74060s - loss: 0\n",
      "Epoch 28/200\n",
      "804/804 [==============================] - 1s 968us/step - loss: 0.5319 - accuracy: 0.7397\n",
      "Epoch 29/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5359 - accuracy: 0.7402\n",
      "Epoch 30/200\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5339 - accuracy: 0.7405\n",
      "Epoch 31/200\n",
      "804/804 [==============================] - 1s 976us/step - loss: 0.5325 - accuracy: 0.7406\n",
      "Epoch 32/200\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5322 - accuracy: 0.7406\n",
      "Epoch 33/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5332 - accuracy: 0.74020s - loss: 0.5339 - \n",
      "Epoch 34/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5327 - accuracy: 0.7406\n",
      "Epoch 35/200\n",
      "804/804 [==============================] - 1s 983us/step - loss: 0.5321 - accuracy: 0.7401\n",
      "Epoch 36/200\n",
      "804/804 [==============================] - 1s 980us/step - loss: 0.5325 - accuracy: 0.7401\n",
      "Epoch 37/200\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5329 - accuracy: 0.7404\n",
      "Epoch 38/200\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5319 - accuracy: 0.7401\n",
      "Epoch 39/200\n",
      "804/804 [==============================] - 1s 969us/step - loss: 0.5322 - accuracy: 0.74040s - loss:\n",
      "Epoch 40/200\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5323 - accuracy: 0.7402\n",
      "Epoch 41/200\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5330 - accuracy: 0.7399\n",
      "Epoch 42/200\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5325 - accuracy: 0.7399\n",
      "Epoch 43/200\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5318 - accuracy: 0.7403\n",
      "Epoch 44/200\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5318 - accuracy: 0.7410\n",
      "Epoch 45/200\n",
      "804/804 [==============================] - 1s 957us/step - loss: 0.5322 - accuracy: 0.7406\n",
      "Epoch 46/200\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5322 - accuracy: 0.7403\n",
      "Epoch 47/200\n",
      "804/804 [==============================] - 1s 980us/step - loss: 0.5321 - accuracy: 0.74050s - loss: 0.5\n",
      "Epoch 48/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5322 - accuracy: 0.7407\n",
      "Epoch 49/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5329 - accuracy: 0.7403\n",
      "Epoch 50/200\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5328 - accuracy: 0.7401\n",
      "Epoch 51/200\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.74 - 1s 964us/step - loss: 0.5323 - accuracy: 0.7404\n",
      "Epoch 52/200\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5325 - accuracy: 0.7401\n",
      "Epoch 53/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5323 - accuracy: 0.74040s - loss:\n",
      "Epoch 54/200\n",
      "804/804 [==============================] - 1s 968us/step - loss: 0.5322 - accuracy: 0.7401\n",
      "Epoch 55/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5317 - accuracy: 0.7409\n",
      "Epoch 56/200\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5322 - accuracy: 0.7402\n",
      "Epoch 57/200\n",
      "804/804 [==============================] - 1s 976us/step - loss: 0.5320 - accuracy: 0.74000s - los\n",
      "Epoch 58/200\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5318 - accuracy: 0.7406\n",
      "Epoch 59/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5316 - accuracy: 0.7407\n",
      "Epoch 60/200\n",
      "804/804 [==============================] - 1s 975us/step - loss: 0.5320 - accuracy: 0.7403\n",
      "Epoch 61/200\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5355 - accuracy: 0.7404\n",
      "Epoch 62/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5362 - accuracy: 0.7397\n",
      "Epoch 63/200\n",
      "804/804 [==============================] - 1s 987us/step - loss: 0.5318 - accuracy: 0.7402\n",
      "Epoch 64/200\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5319 - accuracy: 0.7406\n",
      "Epoch 65/200\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5316 - accuracy: 0.7401\n",
      "Epoch 66/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5322 - accuracy: 0.7403\n",
      "Epoch 67/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5316 - accuracy: 0.7406\n",
      "Epoch 68/200\n",
      "804/804 [==============================] - 1s 980us/step - loss: 0.5316 - accuracy: 0.7409\n",
      "Epoch 69/200\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5320 - accuracy: 0.7400\n",
      "Epoch 70/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7406\n",
      "Epoch 71/200\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5330 - accuracy: 0.7402\n",
      "Epoch 72/200\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5323 - accuracy: 0.7404\n",
      "Epoch 73/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5321 - accuracy: 0.7402\n",
      "Epoch 74/200\n",
      "804/804 [==============================] - 1s 998us/step - loss: 0.5361 - accuracy: 0.73980s - loss: 0.5315 - ac\n",
      "Epoch 75/200\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5330 - accuracy: 0.7405\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 909us/step - loss: 0.5316 - accuracy: 0.74020s - loss: 0.5337 - ac\n",
      "Epoch 77/200\n",
      "804/804 [==============================] - 1s 927us/step - loss: 0.5318 - accuracy: 0.7403\n",
      "Epoch 78/200\n",
      "804/804 [==============================] - 1s 944us/step - loss: 0.5318 - accuracy: 0.7406\n",
      "Epoch 79/200\n",
      "804/804 [==============================] - 1s 960us/step - loss: 0.5320 - accuracy: 0.7406\n",
      "Epoch 80/200\n",
      "804/804 [==============================] - 1s 933us/step - loss: 0.5329 - accuracy: 0.7401\n",
      "Epoch 81/200\n",
      "804/804 [==============================] - 1s 929us/step - loss: 0.5325 - accuracy: 0.74060s - loss: 0.5303 \n",
      "Epoch 82/200\n",
      "804/804 [==============================] - 1s 932us/step - loss: 0.5319 - accuracy: 0.7397\n",
      "Epoch 83/200\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5387 - accuracy: 0.7402\n",
      "Epoch 84/200\n",
      "804/804 [==============================] - 1s 927us/step - loss: 0.5320 - accuracy: 0.7404\n",
      "Epoch 85/200\n",
      "804/804 [==============================] - 1s 933us/step - loss: 0.5318 - accuracy: 0.7411\n",
      "Epoch 86/200\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5315 - accuracy: 0.7405\n",
      "Epoch 87/200\n",
      "804/804 [==============================] - 1s 927us/step - loss: 0.5320 - accuracy: 0.7409\n",
      "Epoch 88/200\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.74 - 1s 928us/step - loss: 0.5314 - accuracy: 0.7408\n",
      "Epoch 89/200\n",
      "804/804 [==============================] - 1s 945us/step - loss: 0.5314 - accuracy: 0.74090s - loss: 0\n",
      "Epoch 90/200\n",
      "804/804 [==============================] - 1s 954us/step - loss: 0.5315 - accuracy: 0.7404\n",
      "Epoch 91/200\n",
      "804/804 [==============================] - 1s 940us/step - loss: 0.5317 - accuracy: 0.7407\n",
      "Epoch 92/200\n",
      "804/804 [==============================] - 1s 944us/step - loss: 0.5321 - accuracy: 0.7395\n",
      "Epoch 93/200\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5317 - accuracy: 0.7402\n",
      "Epoch 94/200\n",
      "804/804 [==============================] - 1s 935us/step - loss: 0.5322 - accuracy: 0.7401\n",
      "Epoch 95/200\n",
      "804/804 [==============================] - 1s 931us/step - loss: 0.5321 - accuracy: 0.7403\n",
      "Epoch 96/200\n",
      "804/804 [==============================] - 1s 933us/step - loss: 0.5319 - accuracy: 0.7403\n",
      "Epoch 97/200\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5319 - accuracy: 0.7407\n",
      "Epoch 98/200\n",
      "804/804 [==============================] - 1s 893us/step - loss: 0.5324 - accuracy: 0.7402\n",
      "Epoch 99/200\n",
      "804/804 [==============================] - 1s 929us/step - loss: 0.5344 - accuracy: 0.74040s - los\n",
      "Epoch 100/200\n",
      "804/804 [==============================] - 1s 949us/step - loss: 0.5321 - accuracy: 0.7405\n",
      "Epoch 101/200\n",
      "804/804 [==============================] - 1s 932us/step - loss: 0.5317 - accuracy: 0.7403\n",
      "Epoch 102/200\n",
      "804/804 [==============================] - 1s 951us/step - loss: 0.5334 - accuracy: 0.7406\n",
      "Epoch 103/200\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5338 - accuracy: 0.7402\n",
      "Epoch 104/200\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5329 - accuracy: 0.74 - 1s 952us/step - loss: 0.5332 - accuracy: 0.7403\n",
      "Epoch 105/200\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5321 - accuracy: 0.7405\n",
      "Epoch 106/200\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5316 - accuracy: 0.74060s - los\n",
      "Epoch 107/200\n",
      "804/804 [==============================] - 1s 933us/step - loss: 0.5322 - accuracy: 0.7406\n",
      "Epoch 108/200\n",
      "804/804 [==============================] - 1s 948us/step - loss: 0.5323 - accuracy: 0.74080s - loss:\n",
      "Epoch 109/200\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5382 - accuracy: 0.7410\n",
      "Epoch 110/200\n",
      "804/804 [==============================] - 1s 942us/step - loss: 0.5328 - accuracy: 0.7408\n",
      "Epoch 111/200\n",
      "804/804 [==============================] - 1s 940us/step - loss: 0.5351 - accuracy: 0.7404\n",
      "Epoch 112/200\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5318 - accuracy: 0.7405\n",
      "Epoch 113/200\n",
      "804/804 [==============================] - 1s 889us/step - loss: 0.5314 - accuracy: 0.74080s - loss: 0.5302 - \n",
      "Epoch 114/200\n",
      "804/804 [==============================] - 1s 975us/step - loss: 0.5317 - accuracy: 0.7406\n",
      "Epoch 115/200\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5324 - accuracy: 0.74040s - loss: 0.5310 - accu\n",
      "Epoch 116/200\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5319 - accuracy: 0.74090s - loss: 0.5300 - accu\n",
      "Epoch 117/200\n",
      "804/804 [==============================] - 1s 933us/step - loss: 0.5317 - accuracy: 0.7400\n",
      "Epoch 118/200\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5345 - accuracy: 0.7405\n",
      "Epoch 119/200\n",
      "804/804 [==============================] - 1s 953us/step - loss: 0.5315 - accuracy: 0.7403\n",
      "Epoch 120/200\n",
      "804/804 [==============================] - 1s 932us/step - loss: 0.5316 - accuracy: 0.7408\n",
      "Epoch 121/200\n",
      "804/804 [==============================] - 1s 943us/step - loss: 0.5325 - accuracy: 0.7410\n",
      "Epoch 122/200\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5320 - accuracy: 0.7404\n",
      "Epoch 123/200\n",
      "804/804 [==============================] - 1s 933us/step - loss: 0.5313 - accuracy: 0.7404\n",
      "Epoch 124/200\n",
      "804/804 [==============================] - 1s 938us/step - loss: 0.5319 - accuracy: 0.7407\n",
      "Epoch 125/200\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5316 - accuracy: 0.7407\n",
      "Epoch 126/200\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5328 - accuracy: 0.7405\n",
      "Epoch 127/200\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5356 - accuracy: 0.7406\n",
      "Epoch 128/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5320 - accuracy: 0.7407\n",
      "Epoch 129/200\n",
      "804/804 [==============================] - 1s 926us/step - loss: 0.5330 - accuracy: 0.7409\n",
      "Epoch 130/200\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5322 - accuracy: 0.7410\n",
      "Epoch 131/200\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.7410 ETA: 0s - loss: - 1s 948us/step - loss: 0.5317 - accuracy: 0.7406\n",
      "Epoch 132/200\n",
      "804/804 [==============================] - 1s 957us/step - loss: 0.5313 - accuracy: 0.74100s - loss: 0.5244 \n",
      "Epoch 133/200\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5312 - accuracy: 0.74040s - loss: 0.5297 - ac\n",
      "Epoch 134/200\n",
      "804/804 [==============================] - 1s 940us/step - loss: 0.5326 - accuracy: 0.7404\n",
      "Epoch 135/200\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5351 - accuracy: 0.7400\n",
      "Epoch 136/200\n",
      "804/804 [==============================] - 1s 943us/step - loss: 0.5315 - accuracy: 0.74090s - loss: 0.5335 - accuracy: \n",
      "Epoch 137/200\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5316 - accuracy: 0.74030s - loss: 0.5314 - accuracy: 0.\n",
      "Epoch 138/200\n",
      "804/804 [==============================] - 1s 958us/step - loss: 0.5316 - accuracy: 0.74100s - los\n",
      "Epoch 139/200\n",
      "804/804 [==============================] - 1s 942us/step - loss: 0.5338 - accuracy: 0.7406\n",
      "Epoch 140/200\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5316 - accuracy: 0.7403\n",
      "Epoch 141/200\n",
      "804/804 [==============================] - 1s 944us/step - loss: 0.5317 - accuracy: 0.7402\n",
      "Epoch 142/200\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5317 - accuracy: 0.7403\n",
      "Epoch 143/200\n",
      "804/804 [==============================] - 1s 968us/step - loss: 0.5312 - accuracy: 0.74070s - loss: 0.5274 - \n",
      "Epoch 144/200\n",
      "804/804 [==============================] - 1s 938us/step - loss: 0.5319 - accuracy: 0.7410\n",
      "Epoch 145/200\n",
      "804/804 [==============================] - 1s 944us/step - loss: 0.5346 - accuracy: 0.7398\n",
      "Epoch 146/200\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5324 - accuracy: 0.7406\n",
      "Epoch 147/200\n",
      "804/804 [==============================] - 1s 948us/step - loss: 0.5347 - accuracy: 0.7407\n",
      "Epoch 148/200\n",
      "804/804 [==============================] - 1s 951us/step - loss: 0.5321 - accuracy: 0.7407\n",
      "Epoch 149/200\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5321 - accuracy: 0.7404\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 934us/step - loss: 0.5315 - accuracy: 0.7406\n",
      "Epoch 151/200\n",
      "804/804 [==============================] - 1s 913us/step - loss: 0.5316 - accuracy: 0.7410\n",
      "Epoch 152/200\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.5314 - accuracy: 0.7409\n",
      "Epoch 153/200\n",
      "804/804 [==============================] - 1s 917us/step - loss: 0.5319 - accuracy: 0.7407\n",
      "Epoch 154/200\n",
      "804/804 [==============================] - 1s 945us/step - loss: 0.5315 - accuracy: 0.7404\n",
      "Epoch 155/200\n",
      "804/804 [==============================] - 1s 926us/step - loss: 0.5314 - accuracy: 0.7409\n",
      "Epoch 156/200\n",
      "804/804 [==============================] - 1s 942us/step - loss: 0.5317 - accuracy: 0.7407\n",
      "Epoch 157/200\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5319 - accuracy: 0.7403\n",
      "Epoch 158/200\n",
      "804/804 [==============================] - 1s 896us/step - loss: 0.5413 - accuracy: 0.7408\n",
      "Epoch 159/200\n",
      "804/804 [==============================] - 1s 942us/step - loss: 0.5335 - accuracy: 0.7409\n",
      "Epoch 160/200\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5341 - accuracy: 0.74070s - loss:\n",
      "Epoch 161/200\n",
      "804/804 [==============================] - 1s 935us/step - loss: 0.5356 - accuracy: 0.7403\n",
      "Epoch 162/200\n",
      "804/804 [==============================] - 1s 934us/step - loss: 0.5330 - accuracy: 0.7408\n",
      "Epoch 163/200\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5330 - accuracy: 0.73 - 1s 927us/step - loss: 0.5316 - accuracy: 0.7406\n",
      "Epoch 164/200\n",
      "804/804 [==============================] - 1s 948us/step - loss: 0.5341 - accuracy: 0.7403\n",
      "Epoch 165/200\n",
      "804/804 [==============================] - 1s 926us/step - loss: 0.5318 - accuracy: 0.7409\n",
      "Epoch 166/200\n",
      "804/804 [==============================] - 1s 949us/step - loss: 0.5317 - accuracy: 0.7407\n",
      "Epoch 167/200\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5316 - accuracy: 0.7413\n",
      "Epoch 168/200\n",
      "804/804 [==============================] - 1s 927us/step - loss: 0.5322 - accuracy: 0.7405\n",
      "Epoch 169/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5310 - accuracy: 0.7404\n",
      "Epoch 170/200\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5314 - accuracy: 0.74030s - loss: 0.5404 - accuracy: 0.73 - ETA: 0s - loss: 0\n",
      "Epoch 171/200\n",
      "804/804 [==============================] - 1s 948us/step - loss: 0.5315 - accuracy: 0.7401\n",
      "Epoch 172/200\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5320 - accuracy: 0.74040s - los\n",
      "Epoch 173/200\n",
      "804/804 [==============================] - 1s 969us/step - loss: 0.5313 - accuracy: 0.7407\n",
      "Epoch 174/200\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5312 - accuracy: 0.74100s - loss: 0.5319 \n",
      "Epoch 175/200\n",
      "804/804 [==============================] - 1s 965us/step - loss: 0.5313 - accuracy: 0.74030s - loss: 0.5254 \n",
      "Epoch 176/200\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.5328 - accuracy: 0.7408\n",
      "Epoch 177/200\n",
      "804/804 [==============================] - 1s 948us/step - loss: 0.5438 - accuracy: 0.7404\n",
      "Epoch 178/200\n",
      "804/804 [==============================] - 1s 932us/step - loss: 0.5315 - accuracy: 0.7409\n",
      "Epoch 179/200\n",
      "804/804 [==============================] - 1s 947us/step - loss: 0.5311 - accuracy: 0.7404\n",
      "Epoch 180/200\n",
      "804/804 [==============================] - 1s 944us/step - loss: 0.5314 - accuracy: 0.7408\n",
      "Epoch 181/200\n",
      "804/804 [==============================] - 1s 969us/step - loss: 0.5314 - accuracy: 0.7411\n",
      "Epoch 182/200\n",
      "804/804 [==============================] - 1s 949us/step - loss: 0.5312 - accuracy: 0.7404\n",
      "Epoch 183/200\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5314 - accuracy: 0.7400\n",
      "Epoch 184/200\n",
      "804/804 [==============================] - 1s 955us/step - loss: 0.5318 - accuracy: 0.7401\n",
      "Epoch 185/200\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5338 - accuracy: 0.7410\n",
      "Epoch 186/200\n",
      "804/804 [==============================] - 1s 960us/step - loss: 0.5360 - accuracy: 0.7408\n",
      "Epoch 187/200\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5313 - accuracy: 0.7408\n",
      "Epoch 188/200\n",
      "804/804 [==============================] - 1s 968us/step - loss: 0.5325 - accuracy: 0.7406\n",
      "Epoch 189/200\n",
      "804/804 [==============================] - 1s 960us/step - loss: 0.5314 - accuracy: 0.74050s - loss: 0.5\n",
      "Epoch 190/200\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5321 - accuracy: 0.7410\n",
      "Epoch 191/200\n",
      "804/804 [==============================] - 1s 915us/step - loss: 0.5312 - accuracy: 0.7406\n",
      "Epoch 192/200\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5312 - accuracy: 0.7406\n",
      "Epoch 193/200\n",
      "804/804 [==============================] - 1s 953us/step - loss: 0.5317 - accuracy: 0.7408\n",
      "Epoch 194/200\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5315 - accuracy: 0.7407\n",
      "Epoch 195/200\n",
      "804/804 [==============================] - 1s 935us/step - loss: 0.5313 - accuracy: 0.7408\n",
      "Epoch 196/200\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.5334 - accuracy: 0.7408\n",
      "Epoch 197/200\n",
      "804/804 [==============================] - 1s 942us/step - loss: 0.5320 - accuracy: 0.7407\n",
      "Epoch 198/200\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5313 - accuracy: 0.7407\n",
      "Epoch 199/200\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5399 - accuracy: 0.7407\n",
      "Epoch 200/200\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5325 - accuracy: 0.74020s - loss: 0.5334 - accura\n"
     ]
    }
   ],
   "source": [
    "# Increasing number of epochs\n",
    "fit_model_inc_epochs = nn_inc_epochs.fit(X_train_scaled, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1e95f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.6200 - accuracy: 0.7346\n",
      "Loss: 0.620000422000885, Accuracy: 0.7345772385597229\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_inc_epochs.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ec1252",
   "metadata": {},
   "source": [
    "# Changing activation function from relu to tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa30ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Activation Function: try tanh to handle negative inputs in X_train_scaled\n",
    "nn_tanh = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78ed697e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 80)                3520      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,981\n",
      "Trainable params: 5,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# First hidden layer\n",
    "nn_tanh.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"tanh\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_tanh.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn_tanh.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_tanh.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f140a04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_tanh.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88b3d337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5707 - accuracy: 0.7196\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5580 - accuracy: 0.72790s - los\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5546 - accuracy: 0.7271\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5527 - accuracy: 0.7282\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5509 - accuracy: 0.7307\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5497 - accuracy: 0.7311\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 928us/step - loss: 0.5488 - accuracy: 0.7322\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5480 - accuracy: 0.7327\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5471 - accuracy: 0.7318\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 947us/step - loss: 0.5466 - accuracy: 0.7343\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 976us/step - loss: 0.5465 - accuracy: 0.7322\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7333\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7347\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 895us/step - loss: 0.5449 - accuracy: 0.7345\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7349\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5437 - accuracy: 0.73450s - loss: 0.5431 \n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7342\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 942us/step - loss: 0.5431 - accuracy: 0.7343\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5428 - accuracy: 0.7351\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5424 - accuracy: 0.7365: 0s - los\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5422 - accuracy: 0.7354\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5416 - accuracy: 0.7369\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5419 - accuracy: 0.7358: 0s - loss: 0.5431 - accuracy: \n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7348\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7364\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.7363\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 864us/step - loss: 0.5411 - accuracy: 0.7369\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 907us/step - loss: 0.5408 - accuracy: 0.7363\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7368\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5405 - accuracy: 0.7365\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7375\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7369\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7376\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5395 - accuracy: 0.7370\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7379\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 1000us/step - loss: 0.5393 - accuracy: 0.7374\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7373\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7386\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7373\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7381\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 995us/step - loss: 0.5384 - accuracy: 0.7372\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7384\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7391\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5374 - accuracy: 0.73 - 1s 982us/step - loss: 0.5381 - accuracy: 0.7374\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 987us/step - loss: 0.5378 - accuracy: 0.7383\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5377 - accuracy: 0.7381\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 987us/step - loss: 0.5375 - accuracy: 0.7385\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 936us/step - loss: 0.5377 - accuracy: 0.73890s - loss:\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7378\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7388\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7386\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7378\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5371 - accuracy: 0.7402\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 977us/step - loss: 0.5371 - accuracy: 0.7378\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 974us/step - loss: 0.5367 - accuracy: 0.73820s - loss: 0.5369 - ac\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5365 - accuracy: 0.7374\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7390\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7387\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7386\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 987us/step - loss: 0.5365 - accuracy: 0.7389\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 958us/step - loss: 0.5364 - accuracy: 0.7389\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 980us/step - loss: 0.5361 - accuracy: 0.7390\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5363 - accuracy: 0.7385\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.5361 - accuracy: 0.7390\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 910us/step - loss: 0.5359 - accuracy: 0.73900s - los\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.73 - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7392\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7391\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7393\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7394: 0s - loss: 0.5373 - \n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7387\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7392\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7387\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7385\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7393\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7395\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7405\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7395\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7393\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 962us/step - loss: 0.5353 - accuracy: 0.7398\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 1s 923us/step - loss: 0.5351 - accuracy: 0.7393\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7395\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7386\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7389\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5349 - accuracy: 0.7397\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 949us/step - loss: 0.5348 - accuracy: 0.73990s - los\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 925us/step - loss: 0.5348 - accuracy: 0.7393\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7397\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 914us/step - loss: 0.5348 - accuracy: 0.7386\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7399\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.5347 - accuracy: 0.7391\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5346 - accuracy: 0.7394\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5348 - accuracy: 0.73950s - l\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7397\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5343 - accuracy: 0.73920s - loss: 0.5384 - \n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7388\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7402: 0s - loss: 0.5353 - accuracy: 0.\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7391\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7388 ETA: 0s - l - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7395\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7396\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7396\n"
     ]
    }
   ],
   "source": [
    "fit_model_tanh = nn_tanh.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fcdf2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5524 - accuracy: 0.7326\n",
      "Loss: 0.5524094104766846, Accuracy: 0.7325947284698486\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_tanh.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a351f54",
   "metadata": {},
   "source": [
    "# Reducing Number of Input Features with additional binning and removing redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1516d8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reducing Number of Input Features\n",
    "# \"SPECIAL_CONSIDERATIONS_N\" and \"SPECIAL_CONSIDERATIONS_Y\" are dedundant, drop \"SPECIAL_CONSIDERATIONS_N\"\n",
    "# Bin categorical columns with more than 5 unique values\n",
    "# Re-read data\n",
    "application_df = pd.read_csv(\"Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "898bc800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-essential columns\n",
    "application_df = application_df.drop(labels=[\"EIN\", \"NAME\"], axis=1)\n",
    "\n",
    "# Bucket \"APPLICATION_TYPE\"\n",
    "replace_application = list(application_counts[application_counts < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    application_df[\"APPLICATION_TYPE\"] = application_df[\"APPLICATION_TYPE\"].replace(app, \"Other\")\n",
    "\n",
    "# Bucket \"CLASSIFICATION\"\n",
    "replace_class = list(classification_counts[classification_counts < 1800].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df[\"CLASSIFICATION\"] = application_df[\"CLASSIFICATION\"].replace(cls, \"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70c44ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "1M-5M              955\n",
       "1-9999             728\n",
       "10000-24999        543\n",
       "10M-50M            240\n",
       "5M-10M             185\n",
       "50M+               139\n",
       "Name: INCOME_AMT, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at INCOME_AMT value counts for bucketing\n",
    "income_counts = application_df[\"INCOME_AMT\"].value_counts()\n",
    "income_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "42045211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                24388\n",
       "25000-99999       3747\n",
       "100000-499999     3374\n",
       "Other             2790\n",
       "Name: INCOME_AMT, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 3000\n",
    "replace_income = list(income_counts[income_counts < 3000].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for income in replace_income:\n",
    "    application_df[\"INCOME_AMT\"] = application_df[\"INCOME_AMT\"].replace(income, \"Other\")\n",
    "    \n",
    "# Check to make sure bucketing was successful\n",
    "application_df[\"INCOME_AMT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2e56ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Independent         18480\n",
       "CompanySponsored    15705\n",
       "Family/Parent          64\n",
       "National               33\n",
       "Regional               13\n",
       "Other                   4\n",
       "Name: AFFILIATION, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at AFFILIATION value counts for bucketing\n",
    "aff_counts = application_df[\"AFFILIATION\"].value_counts()\n",
    "aff_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88214216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Independent         18480\n",
       "CompanySponsored    15705\n",
       "Other                 114\n",
       "Name: AFFILIATION, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than 15000\n",
    "replace_aff = list(aff_counts[aff_counts < 15000].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for aff in replace_aff:\n",
    "    application_df[\"AFFILIATION\"] = application_df[\"AFFILIATION\"].replace(aff, \"Other\")\n",
    "    \n",
    "# Check to make sure bucketing was successful\n",
    "application_df[\"AFFILIATION\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a9d9217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a8702d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "application_df = application_df.merge(encode_df, left_index=True, right_index=True)\n",
    "application_df = application_df.drop(labels=application_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2037c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_Other</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   USE_CASE_ProductDev  ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                  1.0                       1.0                        0.0   \n",
       "1                  0.0                       0.0                        1.0   \n",
       "2                  1.0                       1.0                        0.0   \n",
       "3                  0.0                       0.0                        0.0   \n",
       "4                  0.0                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  INCOME_AMT_0  \\\n",
       "0                       0.0                 0.0           1.0   \n",
       "1                       0.0                 0.0           0.0   \n",
       "2                       0.0                 0.0           1.0   \n",
       "3                       0.0                 1.0           0.0   \n",
       "4                       0.0                 1.0           0.0   \n",
       "\n",
       "   INCOME_AMT_100000-499999  INCOME_AMT_25000-99999  INCOME_AMT_Other  \\\n",
       "0                       0.0                     0.0               0.0   \n",
       "1                       0.0                     0.0               1.0   \n",
       "2                       0.0                     0.0               0.0   \n",
       "3                       0.0                     0.0               1.0   \n",
       "4                       1.0                     0.0               0.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop \"SPECIAL_CONSIDERATION_N\":\n",
    "application_df = application_df.drop(\"SPECIAL_CONSIDERATIONS_N\", axis=1)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea73678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = application_df[\"IS_SUCCESSFUL\"].values.reshape(-1, 1)\n",
    "X = application_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc919306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae5e0ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 80)                2800      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 30)                2430      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 5,261\n",
      "Trainable params: 5,261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 80\n",
    "hidden_nodes_layer2 = 30\n",
    "\n",
    "nn_reduced_input = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_reduced_input.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_reduced_input.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_reduced_input.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_reduced_input.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33f3983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5717 - accuracy: 0.7193\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5590 - accuracy: 0.7276: 0s - loss: 0.5594 - accuracy: 0.72\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5563 - accuracy: 0.7290\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5541 - accuracy: 0.7299\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5523 - accuracy: 0.7317\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5529 - accuracy: 0.7294\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 1s 914us/step - loss: 0.5504 - accuracy: 0.73230s - loss: 0.5541 - accu\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5513 - accuracy: 0.7312\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5500 - accuracy: 0.7302: 0s - l\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 1s 914us/step - loss: 0.5498 - accuracy: 0.7315\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 1s 946us/step - loss: 0.5493 - accuracy: 0.7321\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 1s 932us/step - loss: 0.5488 - accuracy: 0.7319\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5490 - accuracy: 0.7319\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 1s 873us/step - loss: 0.5480 - accuracy: 0.7315\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 1s 956us/step - loss: 0.5481 - accuracy: 0.7320\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 1s 968us/step - loss: 0.5473 - accuracy: 0.73230s - loss: 0.5473 - accuracy: 0.73\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5469 - accuracy: 0.7331\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7323\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7310\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.73 - 1s 1ms/step - loss: 0.5464 - accuracy: 0.7344\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5457 - accuracy: 0.7329\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 1s 961us/step - loss: 0.5455 - accuracy: 0.7345\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5456 - accuracy: 0.7334\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7336: 0s - loss: 0.5456 - accuracy: 0.73\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 1s 945us/step - loss: 0.5452 - accuracy: 0.73450s - loss:\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5445 - accuracy: 0.7345\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 1s 945us/step - loss: 0.5446 - accuracy: 0.7355\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 1s 944us/step - loss: 0.5442 - accuracy: 0.7346\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7355: 0s - loss: 0\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5441 - accuracy: 0.7347\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5440 - accuracy: 0.7345\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.7354\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5432 - accuracy: 0.7360\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5434 - accuracy: 0.7360\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7348\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7372\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7357\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7360: 0s - l\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 1s 926us/step - loss: 0.5421 - accuracy: 0.7360\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5415 - accuracy: 0.7367\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 1s 912us/step - loss: 0.5425 - accuracy: 0.7369\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7376\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 1s 922us/step - loss: 0.5418 - accuracy: 0.7367\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 1s 919us/step - loss: 0.5415 - accuracy: 0.73650s - loss: 0.5415 - accuracy: 0.73\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 1s 948us/step - loss: 0.5416 - accuracy: 0.7363\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 1s 957us/step - loss: 0.5413 - accuracy: 0.7377\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 1s 986us/step - loss: 0.5417 - accuracy: 0.7379\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 1s 960us/step - loss: 0.5414 - accuracy: 0.7361\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 1s 987us/step - loss: 0.5409 - accuracy: 0.7371\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7366\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7378\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5411 - accuracy: 0.7372\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 1s 915us/step - loss: 0.5405 - accuracy: 0.7376\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5409 - accuracy: 0.73780s - loss: 0\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 1s 959us/step - loss: 0.5403 - accuracy: 0.7393\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7363\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5401 - accuracy: 0.7377\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7377: 0s - l\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7381\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5398 - accuracy: 0.7374\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7383\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7376: 0s - loss: 0.5393 - accuracy\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5394 - accuracy: 0.7378\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7387\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7376\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 1s 957us/step - loss: 0.5392 - accuracy: 0.7391\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5397 - accuracy: 0.7389\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 1s 995us/step - loss: 0.5396 - accuracy: 0.7371\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7384\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5380 - accuracy: 0.7388 ETA: 0s - loss: 0.5 - 1s 997us/step - loss: 0.5391 - accuracy: 0.7380\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7378: 0s - loss: 0.544\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7385\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 1s 991us/step - loss: 0.5389 - accuracy: 0.7385\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5386 - accuracy: 0.7389\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5389 - accuracy: 0.7390\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5390 - accuracy: 0.73830s - loss:\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 1s 992us/step - loss: 0.5384 - accuracy: 0.7377\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7382: 0s - loss: 0.5404 - ac\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.73 - 1s 932us/step - loss: 0.5387 - accuracy: 0.7376\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 1s 906us/step - loss: 0.5384 - accuracy: 0.7392\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 1s 946us/step - loss: 0.5382 - accuracy: 0.73900s - loss: 0.5314 - \n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5385 - accuracy: 0.7385\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7391\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7381\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 1s 930us/step - loss: 0.5380 - accuracy: 0.7391\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5388 - accuracy: 0.73 - 1s 929us/step - loss: 0.5383 - accuracy: 0.7389\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 1s 917us/step - loss: 0.5382 - accuracy: 0.7384\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5380 - accuracy: 0.7379\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 1s 926us/step - loss: 0.5380 - accuracy: 0.7397\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 1s 971us/step - loss: 0.5374 - accuracy: 0.7378\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 1s 959us/step - loss: 0.5379 - accuracy: 0.7380\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5377 - accuracy: 0.7382\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 1s 956us/step - loss: 0.5383 - accuracy: 0.7390\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 1s 951us/step - loss: 0.5377 - accuracy: 0.7375\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 1s 966us/step - loss: 0.5375 - accuracy: 0.7392\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5380 - accuracy: 0.7386\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5379 - accuracy: 0.7393\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 1s 937us/step - loss: 0.5373 - accuracy: 0.73880s - loss: 0.5370 - accuracy: 0.\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 1s 932us/step - loss: 0.5376 - accuracy: 0.7384\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn_reduced_input.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model_reduced_input = nn_reduced_input.fit(X_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1606e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5613 - accuracy: 0.7269\n",
      "Loss: 0.5613309144973755, Accuracy: 0.7268804907798767\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_reduced_input.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21838876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAccAAAEGCAYAAAAQSF6jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABZlklEQVR4nO2dZ5gUVdaA38MMQYIgooCgEkQBySKgKKBiQgRZAxhZE2sWXV11/RbD6i5m1xxZMSEmFBUxgaKsIlEkKiBKBslZZuZ8P04VU9P0zPSEppmZ8z5PPVV1Q9W9DdOnz70niKriOI7jOE425VI9AMdxHMfZ03Dh6DiO4zgxuHB0HMdxnBhcODqO4zhODC4cHcdxHCeG9FQPYHdQrlw53WuvvVI9DMdxnBLFli1bVFXLpBJVJoTjXnvtxebNm1M9DMdxnBKFiGxN9RhSRZn8ReA4juM4eeHC0XEcx3FicOHoOI7jFAoROUVE5orIPBG5NU79zSIyLThmiEimiNSM1KeJyFQR+TBSVlNEPhORn4PzPpG624J3zRWRk5M5NxeOjuM4ToERkTTgSeBUoDlwrog0j7ZR1QdUtY2qtgFuA75S1TWRJtcDs2MefSvwhao2Ab4I7gme3Q84HDgFeCoYQ1Jw4eg4juMUhg7APFVdoKp/AG8AvfNofy4wLLwRkfrAacALMe16A0OD66HAGZHyN1R1u6r+AswLxpAUXDg6juM4uZEuIpMix4BIXT1gUeR+cVC2CyJSGdP23okUPwr8DciKaV5bVZcBBOf9C/q+4qBMuHI4juM4hSJDVdvnUidxynJL83Q6MD5cUhWRnsBKVZ0sIt0SHEtB3ldkXHPMiw8/hMGDUz0Kx3FKMB98AL/+mupRJIXFwIGR+/rA0lza9iOypAp0BnqJyEJsOfZ4EXk1qFshInUBgvPKQryvyLhwzItPPoH770/1KBzHKaFs3Qp9+sB996V6JElhItBERBqKSAVMAI6MbSQi1YGuwPthmarepqr1VbVB0G+Mql4QVI8E+gfX/SP9RgL9RKSiiDQEmgDfF/+0DF9WzYvKlcEj6ziOU0jmzIHMTJgxI9UjKX5UNUNErgE+AdKAIao6U0SuCOqfCZr2AT5V1US/TAcDb4rIpcBvwNnB82aKyJvALCADuFpVM4tvRjkR1aQt2e4xVKlSRQsVPu7uu+GOO2DHDkj33xGO4xSMl1+G/v2hZk34/XeQeLtmezAiskVVq6R6HKnAl1Xzokrwf2LLltSOw3EirF4NP/yQ6lE4iRBqjGvWwMqVebctLD/9BH/5C6xbl5znl1VcOOZFKBx9adXZg7j9djj+eCgDiz5J4bvv4NFHbT8w2fz4I5QLvmVnzizas7ZvhyVLdi3/29/guedg4MCiPd/JiQvHvKhc2c4uHJ09iPHjTRPZsCG145gyBT7/fPe9748/iucHwZ13wg03QIsW8PHH8dusXg2vvbbr+3bsgP/+1+oTYcYMOO44u541K7E+mZmQkbFr+eDBcMghpimG/PgjvP8+NGoEQ4fatVM8uHDMC9ccnT2MjRuzNZB4WsTu5OKL4cQToVcvWLgwee+ZNw8uucR+qw4fXrRnqZpQ79wZypeHHj1sTzBWCP71r3DBBTBxYs7yV16xsRx2GAwZAlmx7usR1q6FxYvtM6pRI3HN8fLLbWUglm+/hW3b4Mors8f7739D1ar2g6l1axgwwPY2naKTVOGYQFDabiKyPhKYdlBQflikbJqIbBCRgUFdrkFpix3fc3T2MCZNyv5iXLw4dePYuNG0lk6dYMwYaN7cNKriZNMmE1yHHQbDhkHFiuZ6XBSWLoVVq6BfP9u3vflmM5p5883sNj/9ZEIQdhXGw4fDgQdCs2Zw6aXQpQssXx7/XaEwbNkSDj88MeG4dq1prOPH5/zaUYWpU2G//ezzfuUV+9EwfLgJyzp1bB5r1+YUnk4RUNWkHJhp73ygEVAB+AFoHtOmG/BhAs9ZDhwc3N8P3Bpc3wrcl99YKleurIVi3DhVUP3ss8L1d5xi5t//tv+SoDpkSOrG8fnnNobRo1V/+031yCNV69Ytvuf/8YfqySerliun+te/qi5bpnrWWaoHH1y0544caeMeP97uMzJU27ZVPfBA1c2brey881QrV1bt3Fm1Xj3VzEwrX7lSNS1N9bbbrGzIENW99lLt0UM1K2vXdz31lL3rt99UBwxQrVkzfrsoTz+d/e8bjlFVdckSK3vkEdWjjlLdd1/VP/1JtWJF+2xC/vUva/f664X+iHIAbNYkyYg9/Uim5ljQoLS5cQIwX1XDGBO5BaUtfnxZ1dnDmDABDjrIrneX5vivf8Ho0TnLvvvOzh07miZ1zjmwbFnie3F5kZVlS5effALPPgsPPmia0THHWKSZosx7yhRzp2jVyu7T0uCxx2DRInPUnzXLtNRrrzUNbMkS+N//rO2779p+YN++ZmRz8cXWZ9QoW2KNZcYMqF4d6tc3zToRi9WhQ6095FzSnTbNzkccYZ/J+vU2nssus88m5OabTZu/+mrTkp3Ck0zhmGiQ2KNE5AcR+VhEDo9THxt2KLegtDkQkQFhsNyMeLvbieAGOc4ehKoJxy5dbHltd+w5Ll5s1rF33ZWz/NtvbWmxRg27b9HCzoVxdle1Jc7vv7dj4EB49VW45x778g855hg7jx9f8HeETJliy7RVq+Z87rnnWjCsq6+238Q33WR7qZUqZS+tDh9ufUPBCtb+uONszLH7rj/+aJ+LiC2rQt5GOXPn2o+O66+HAw6wJfSQqVPt3Lq1LdPefjtUq2bCMEp6ugnYbdts79KXVwtPMoVjIkFip2DLpa2Bx4H3cjzAQhL1At4q6MtV9TlVba+q7dML68DvmqOzB7F4sWlnHTtCvXq7R3N8K/jLmzABVqywa1X7Ej/qqOx2LVvauTDC8c03oU0bm1fHjvD446a5/f3vOdu1bm1/kt98U/B3hEydCu3a7Vp+//2mDX75pQm6WrVM+Jx2Grz9tv0Q+eor0xqjjvzlypnWKGKaZGigo2qfRfijoXmQ5TCvfceXX7bnnX8+tG+fUzhOmwaNG8Pee9v9nXeaZnjwwbs+59BDzbI1N43WSYxkCsd8g8Sq6gZV3RRcjwLKi0itSJNTgSmquiJSlltQ2uLHDXKcPYgJE+zcsaMtve0OzXH4cBMUqvDRR1Y2b54tn3bqlN3ugANMi/zxx5z9x4+HG280N4zceOQRaNLEnv/RRzBunPkhxkaTSU+3dxZWOK5aZcun8YRj/fpm+XnIITbekL59zeDmuutM8PXtu2vfBg1sDl9+af6GYD9i1q7N/tFQt27eFqtZWWZkc/LJ1rZ9e9MkQ3edqVPtB0SUqPYbyzXXQLdu8TVaJzGSKRzzDUorInVE7E9ARDoE44nuWuRIjhmQW1Da4sc1R2cPYsIEs9hs3bp4NMfMTHjggdytLRcutHf+9a+2r/jBB1Ye7jdGNUcREwSxmuPjj5vgiGpVsXOaMMGWEnv0sOPYY7Md52M55hiYPj1baGRkQNeuti+ZH+HSZNu28euvu84sVfeJ2L+fdpp9Dbz7rs0v1ABjueQSE0a33257i+GPhFBzDJdWc1tWHTvWBHf/4Jutfftst5P162H+/NzHHY9y5cx6+IADUu/yU1JJmnBU1QwgDEo7G3hTg6C0YWBa4Cxghoj8ADwG9AsspMLkmCcC78Y8ejBwooj8HNQnL6dUhQr2v8yFo7MHMGGCfUFWqGCazu+/295SYRk92qKr3HFH/PrQvaFvXzj9dPj0U3vfd9/ZkmOzZjnbt2hhwjHc51I1LXD//eH1103Ixu6BPf64LRVedFFiY+7c2YRsKKBfftnecccduxqgDBpkgjlkyhQ75yVkYrXVypVt7hBfa4z2+89/LITbHXdk/0gIhSOYYJ05c9fPYPlyC+NcvTr0DkwW2wcZFCdNsh8D+Y07Hg0amDDu3Llg/ZyAVJvL7o6j0K4cqqrVqqlef33h+ztOMbBjh7kXhP8VhwxRBdX58/Pv+8sv1m/16pzlZ59tz6hYUXXFil37tWun2qGDXY8ebW0/+shcH7p337V91HVBVXXePLt/6il7P5grSsjSparly6sOHJj/HEI2bDD3jn/8Q3X7dtUGDVSbNrXnXH55dru33rL3pafb/MP5NmyY+LtCPv/cvgYWLMi/7VVX2fg6dtzVteXRR21My5fbfUaG6hNPqFavrlqhguozz+Rsf/DBqn37qv7nP9ZvyZKCj72oUIZdOVI+gN1xFEk41qmT86/OcfJg9WrVhx6yL/HiZOpUzeG/9skndj9uXN79VqxQPeQQa3vrrdnla9bYF3KPHqoiJmyi/PST9XnoIbvftk21alXVCy80X7//+79d3xW6BX/0kd2HAnzGDPMLPO88u7/kEtVNm1TvuMPe/fPPBfss2rVTPe44EyagOmqUCd9y5VRnzTK/v333VW3Z0gT/JZdYv0MOUT3zzIK9q6D8/rv5M4LqiSfmrPv0UysfM0Z14kTV9u3tvnt31blzd33WmWeqNm6sevHFqvvvn7+PZDJw4VjKjyIJx8aN7a/acfLhm2/MmRx21QLyIisr/y++UBCEmuLMmZqvs/eGDapHHGGO6h07mvazZo3Vhc7mkyer9u5tX+ihE7yq6j//qTm0QFVzOi9XTnMIwChr1ljdfffZ/cUX23NDJ/odO0yoipi2t//+qj175j3veFx3nWnR9eubQ3xWluqqVap7721z6dXLhOLMmSY009JUJ02ysd17b8HfV1CefNLedeONOctDR/7Wre0zqFNHddiw3P/tBw+29g0aqJ50UtKHHRcXjqX8KJJwbNnS/uIcJxeysuxLNy1NtVEj1SpVVK++OvH+Rx2lesUVuddPmKDarJnqfvtlf5GuW2d/vQ88kN1u61YTWu+/b0f37jamDz5QnTbN2t99t7Xt1Em1RQt73tdfW92TT1rdsmWqTZpYhJgoL72kO6O3/P57/LHWq6d6wQV23bhx/D+dL74wwQCmAReU4cOzx/H559nl996bXR5qvMuW2Y+Dww7TnVpmstmxQ/Wmm1R/+CFneVaWabTlypmAX7cu7+eEUYhA9ZZbkjfevMhPOAKnAHOBeQSRy2LqbwamBccMIBOoCVQCvscip80E7or0GR7psxCYFpQ3ALZG6p7Ja2xFPVIuuHbHUSTh2KlT/A0Wp9SyY8eu+3N5MXas/SWdc47q+vUm7Lp2Tazvb79Z33LlVGfPzlm3Zo0JTRHVAw7I+cWelWXLnNHt8HBPK3pEQ8z17Gma3OTJOQVrVpb9N2/cOOce2IgROcezcqWN5dBDc5/PKaeotmmTrSU9+GD8ditXqr73XuGWCsNnd+mSs//mzbZP162b7eeF3HRT9ucR7velim+/VZ0+PbG2oSYOpmGmgryEIwmECI1pfzowJrgWoGpwXR6YAHSK0+chYJBmC8cZuT2/uI+UC67dcRRJOJ5wgurRRxe+v1PiGDjQfuFv2pRY+7vvNqERagKJxtFUVX3xRd1pOHLuudnlW7fa8lu5cjae9et37XvYYRZvNORPfzLhMHmyHaEhSsi339q7Dj7Ynrt0aXbd229nfxGfcEL8PTBV1YsuUr3rrtznc9NNtqT56qv2rO+/z3v+heXpp+OPcf16+3ETZeVK0+YPOCA5Y0km4X7xnDmpeX8+wvEo4JPI/W3AbXm0fx24PE55ZSwgTMeYcsGirDVRF457oHDs1cu+pZwywdKl9uUOqq+8klifU09VPfzw7PvHHrP+UeGTG337mlXjrbeagP3xRyu/8kp7xgcf5N73hBNM41M1QVynTvaSZm4cf7w999RTc5ZnZNgeWV57YIkwdGi2gK1SZVdBlSpefVX1+edTPYqCc955tkIQ1YR3J/kIx7OAFyL3FwJP5NK2MrAGqBkpSwuWRzcRJ4EE0AWYFLlvAGwGpgJfAcfmNrbiODyfY35UqeJ+jmWIhx+2hLa1a8NLL+XfXtV87qLRYsKoKLHRYmLJyrJkwSedZLE8q1a1GKZvvQVPP21xM3v2zL1/vXrZDt4LF5q/3NFH5/3Of/zDztGYpWABuB96yFI5xfr6FYTQr++LL2wshY3cWNycf/6ucy4J/OtfFjUoLS1lQ0gPY1QHx4BIXSIhQkNOB8ar6pqdDVUzVbUNFj2tg4i0iOkTGwRmGXCQqrYFbgReF5G9CzifhHHhmB+VK7twLCFcc41FGiksq1ebUOrXD664wvLmLVqUd5+ffrIwYdFoMYkG4Z461d554omw776Wnf7tty3aSqdOcO+9efevX98c3zMzszNH5Cccu3WzOf3pT3m3KyzNmmVHtzn22OS8oyxx8MEWaD6FZGgQozo4novU5RsiNEJsAomdqOo64EvMuAcAEUkH/oQZ54Tttqvq6uB6MrbfeWhBJ5QoLhzzo0oVj61aAli/Hp58Ep5/vvDPeOwx+x10220WsUU1O+ltboSRWqKaY61alkYoP83x00/t3L27nW+4weJvpqdb2qTy5fPuX6+eCcaVK004Vq2aMyJLboQpkZLBXntZnFRI+Ze6k3zyDREKICLVga5EQn2KyH4iUiO43gvoDsyJdOsOzFHVxTF90oLrRkATYEFxTyrEhWN++LJqiSAMrhzNgVcQNmww4XjGGSZgGjUyzWfo0LzT/nz7rYU/yy2UWsiOHaa1/fe/2WWffmrBpGvXtvsaNaxs3DgL/ZUfoZBbvNgCfHfqlNLlt520aGGCvUOHVI/ESSaaWIhQgD7Ap6oa/SKtC4wVkemYkP1MVT+M1MfTNLsA04Nwo28DV0SXaYudZG5o7ilHkQxy7rnHLAy2by/8M5ykM2KE7rS2LIgbhqrqli0WBAkscknICy9Y2bff5t63detdI6Goqt5wg/nXhQ7wH39sz6pQwaLdbNpkIc9uvrlgY40SOrYPHWrWp4MGFf5ZxcmkSYkbMzl7NpThIACuOeaHJzwuEUTT8hREexw1yrIlPP+85RAMAz4DnH22LRMOHRq/78aNtnQa3W8MadECtm6FBcGiz/DhpmHWqgXnnAMffmja5EknJT7WWELN8d13zbgnv/3G3cURR8AFF6R6FI5TNFw45oenrSoR/PKLZW2HxIXjP/5hKYkqVjTjm8cey1m/997Qp49llPj++137T5pkQim63xgSTf67fTuMGGFLtsOGWfqhSy6x8YbZ7QvDfvvZ8uXo0WZhGm8cjuMUDheO+eEJj0sEv/xihiBNm8YXZLGsXGk5AM8+G374AY47Ln67//s/2wvs3NnaR3MShsY4HTvu2q95cxNYP/5o+4jr11vKoy5dLIv7li12HQr0wlCunOXr277dNNXq1Qv/LMdxcrKHeCHtwbjmWCJYuBAaNjRB9skntvuYl7/eU09ZbsJ//tPyI+ZGs2YwbRpceqn5HX7xhS2z7r+/GeMcdhjUrLlrvypVzKhnxgzL6L7PPtlWqX//u7lw9OhRhAkH1KsHv/665yypOk5pwTXH/HDhuMejappjw4Zw5JGwYoVZcObGli3m9tGrlwm3/NhnH3jnHeszdqxZmI4ZY5pjvP3GkBYtbOn1/ffNrzAUwmlp8OijRdtvDAn3HV04Ok7x4sIxP9wgZ49n9WrYtMncH0L3gbyWVl9+GX7/3aLSJIoIXHWVPbd6dTjhBFi1Ku99vpYtzSBn06a8s8gXhXr17OzC0XGKFxeO+eF7jns8oaVqw4bQurUZqeRmlJOZaSHiOnQonDFMq1amDV58sRnyHH987m1Dh/z99st9T7Oo9O0L118PjRsn5/mOU1bxPcf88GXVPY5Nm+yfJdxT/OUXOzdsaAKrdeucmuP27WaAA7Yc+vPP8OabhY8hWqUKDBlioeYqVsy9XWixetZZyYsx2rFjfIMgx3GKhmuO+eHCMeWomp/gxRebkUu1araPFxIKxzCqTIcO2W4W8+fbvuJBB9nx5z+bEC2O2KJ5CUYwy9m77oK//a3o73IcZ/eSVOEoIqeIyFwRmScit8ap7yYi60VkWnAMitTVEJG3RWSOiMwWkaOC8jtFZEmkTzHY/OWB7zmmnCFDLBj4yJGmFVarZk70IQsXmsXo3kF8/g4dzEH/gw+ga1fTNJ98El54wY4PP9w9YdbKlYNBgxILBec4zp5F0pZVgwCxTwInYtHbJ4rISFWdFdP0a1WNl5jnP8BoVT0rCGpbOVL3iKo+mJSBx+J7jill3ToLBN65s8UcLVcOeveGr77KbvPLLzkF0JFH2vlPf7JsF2PHZi9xOo7jJEIyNccOwDxVXaCqfwBvAL0T6Rjk6OoCvAigqn+opTXZ/ZQvb4drjinh7rvNsvSxx7JTIXXtCvPmZecyDN04Qg47zNwv9tsPvvzSBaPjOAUnmcKxHhDNhrc4KIvlKBH5QUQ+FpHDg7JGwCrgvyIyVUReEJEqkT7XiMh0ERkiIvvEe7mIDAgTdGZkZBRtJp6ZIyXMng2PP25Jatu1yy7v2tXOX31l+5G//ppTOKalmbY4ebJFqnEcxykoyRSOiWSJngIcrKqtgceB94LydKAd8LRa1ufNQLhn+TTQGGiDZYZ+KN7LVfU5DRJ0phfVVNATHheKZ5+FgQN3LV+61PYP80LV+lapsmvS3zZtbH/xq69g+XKLdBO7r9e6dbYPoOM4TkFJpnDMN0u0qm5Q1U3B9SigvIjUCvouVtUJQdO3MWGJqq5Q1UxVzQKex5Zvk4trjgVGFQYPhv/8J9uaNORvf7N9w1mxu88RvvrKYpLeeactj0ZJS7Nci19+mdONw3Ecp7hIpnDMN0u0iNQRMW8zEekQjGe1qi4HFolIGNzrBGBW0K5u5BF9gEhK2SRRpYob5BSQH37Ids5/5ZXs8rVr4e237frxx3Pv/9prltn+L3+JX9+1K/z0k8U3BReOjuMUL0kTjppYluizgBlBZufHgH5Bgk2Aa4HXgkzRbYB/BeX3i8iPQflxwA3JmsNOXHMsMO+9ZwY0bdpYuLbwX/X1180pv2NHK1+7dte+O3ZYjsLevS2fYjy6dbNzmGvx4IOLeQKO4+RLAu56N0fc7maISKaI1BSRSiLyfWBvMlNE7or0ydVdT0RuC941V0ROTurkUp1teXcclStX1iJx0kmqHTsW7RlljFatVI89VvWll1RB9euvVbOyVFu3Vm3bVnXKFCt/8MFd+44aZXUjR+b+/B07VKtVs3a1aydtGo5TpgE2ay7fq0AaMB8zoKwA/AA0z6P96cCY4FqAqsF1eWAC0Cm4vxO4KU7/5sE7KgINg3en5fa+oh4eIScR3CCnQCxYANOnW3LfM880xXvoUJgyxZZbL7sM2ra1fcMnnrB4p1HeeMOCe+eVtSI93XwfwZ3sHSdFFNRd71xgGEAgezcF5eWDI9ZgM5bewBuqul1VfwHmkUSbExeOieB7jgUiDO12xhm2b3jmmRbL9IknLLnveedZ/fXX275kNNrNtm22JNunT/7h2cKlVd9vdJykkR66xAXHgEhdou56iEhl4BTgnUhZmohMA1YCn2m2ASbEd9dL+H3FgQvHRPA9xwIxYoRlr2jUyO7794cNG+CllywId40aVt67Nxx4oFm0hnzyibXt1y//94T+ji4cHSdpZGjgEhccz0XqEnHXCzkdGK+qa3Y2NK+DNpgnQwcRCfLY5OquV5D3FRkXjongwjFhVq6E8eNN8wvp1s2CfoMtqYakp8N115nD/kUXWQzU4cMt5FteqaBCjjjCtNDeCcVdchynmMnXXS9CP4Il1VjUop99iWmWebnrFeR9RcZTViVCuOeoWvg8R2WEDz6wbBhnnJFdVq6c+TaOHAlduuRsf8MN9tHefTd8950FCDj/fIvYlx/ly5vLh+M4KWGnux6wBBOA58U2EpHqQFfggkjZfsAOVV0nInsB3YH7grq6qrosaBp11xsJvC4iDwMHAE2APNKaFw3XHBOhShUTjNu3p3okSWP69Gx3ixBVuOMOq8uLZ56xJc4GDcwv8eCDLUJNlKuvtiXT2N8WaWn2jjFjbFt382ZL4Os4zp6NJuauBybgPlXV6PJbXWBs4JI3EdtzDK0P4rrrqepM4E3M5300cLWqxpjzFR+isd+IpZAqVaro5qIsiz72mFmP/P67rfmVMn7+GQ491Ixmzj47u/zXX03gnXuu+SfGY/NmqF0b6tSBTp2sfc+edl1Qfv8dvvnGlkldQXec1CMiW1S1Sv4tSx++rJoI0YTHpVA4hpFs/ve/nMJx8mQ7f/QR/PEHVKiwa9/337ePZciQXZdMC0qtWjmXYx3HcVKFL6smQlQ4lkKWBav7EyfmLA+F44YNZjQTj9deM4vTY45J3vgcx3F2Ny4cE6FykGe5lPo6Ll9u56lTIZrda/JkaNrUfhu8996u/Vatsn3E887LzrXoOI5TGvCvtEQo5ZpjKBy3bIE5c+xa1YTj0UfDqafa8mlWVs5+b75p0W3OP3/3jtdxHCfZuHBMhDIgHMP9xEmT7LxokRnIHHGE+SwuWwbfxxhNv/YatGxph+M4TmnChWMilAHheMQRUK1a9r5juN94xBHQo4c57I8Ykd1nwQJLF3XeLl5NjuM4JR8XjokQ7jmWYuF4wAEmCEPNcfJk80Fs1crCvR13nAnHaOopMDcPx3Gc0oYLx0QINcdSbJBTpw60b29ZM/74w4Tj4Ydn51Ps08f8Id98EwYOhAcftKwankfRcZzSiAvHRCjFy6rbt1vC4VA4bt8OM2aYcDziiOx2vXrZuV8/ePppOPFEePbZ1IzZcRwn2XgQgEQoxcuqK1bYORSOYMunq1blFI716sGTT5rLRt++sM8+uz7LcRyntODCMRHS0iy5YCkUjqEbR506lmJqn33gxRetLCocAa66aveOzXEcJ1X4smqilNCEx2vWWB7F3ELoRoWjiGmPy5bZ74HY4OGO4zhlhaQKRxE5RUTmisg8Ebk1Tn03EVkvItOCY1CkroaIvC0ic0RktogcFZTXFJHPROTn4Lx7FvhKaE7Hf/8bLr4Yvvgifn0oHOvWtXO4tNq8ebYxjuM4TlkjacJRRNKAJ4FTgebAuSLSPE7Tr1W1TXDcHSn/DzBaVZsCrbGUKAC3Al+oahPgi+A++ZRA4fjHHzB0qF0//XT8NqFw3H9/Ox95pJ1jl1Qdx3HKEsnUHDsA81R1gar+AbwBJJSzXUT2BroALwKo6h9BtmiCZwRf+QwFzijGMedOCRSOH35ohjXt21v4tyVLdm2zfLllwwiTC3fsaA7/nTvv3rE6juPsSSRTONYDFkXuFwdlsRwlIj+IyMcicnhQ1ghYBfxXRKaKyAsiEuYUqx1miQ7O+ydp/DmpXLnE7Tm+8IJZmb72msVADQ1tooQ+jiEHHGDxVS++ePeN03GckkkCW2c3R7bNZohIZrA1VklEvg+++2eKyF2RPg8E22nTRWSEiNQIyhuIyNbI855J5tySKRzjpauNNQuZAhysqq2Bx4H3gvJ0oB3wtKq2BTZTwOVTERkgIpNEZFJGNNVEYSlhmuOiRZYx4+KLLZHxySfDc8/lzLoBuwpHgMaNzSDHcRwnNxLZOlPVB8JtM+A24CtVXQNsB44PvvvbAKeISJgi/TOghaq2An4K+oXMj2zDXZHE6SVVOC4GDozc1weWRhuo6gZV3RRcjwLKi0itoO9iVZ0QNH0bE5YAK0SkLkBwXhnv5ar6nKq2V9X26enF4LFSwoTjSy9ZFo1LLrH7K66wZdUPP8zZLp5wdBzHSYCCbp2dCwwDUGNTUF4+ODSo+1RVw5/x32GyY7eTTOE4EWgiIg1FpALQDxgZbSAidUREgusOwXhWq+pyYJGIHBY0PQGYFVyPBPoH1/2B95M4h2xKkHDMyoIhQ+CEE6BhQyvr2dOWWJ+JLESounB0HCdP0sMVuOAYEKlLdOsMEakMnAK8EylLE5FpmILzWUQZinIJ8HHkvmGw1faViBxbuCklRtKEYyD5rwE+wSxN31TVmSJyhYiE6vBZwAwR+QF4DOinutMj71rgNRGZjqnd/wrKBwMnisjPwInBffKpXLnQwnHdOmjWDL75pniHlBujR8PChXDZZdll6elw+eW21Prrr1a2cSNs3erC0XGcXMkIV+CC47lIXSJbZyGnA+ODJVVrqJoZLLfWBzqISItoBxG5HcgAXguKlgEHBVttNwKvB8abSSGpfo6qOkpVD1XVxqp6b1D2jKo+E1w/oaqHq2prVe2kqv+L9J0W/GO0UtUzVHVtUL5aVU9Q1SbBeU38txczRQgCMHu2GbmEbhWJkJGRu+N+XkycaMmHGzaEM87IWXf22XYOfR6jAQAcx3EKSL5bZxH6ESypxhJ4InyJaZYAiEh/oCdwfqgwqep2VV0dXE8G5gOHFmkGeeARchJl331NOG7YUOCuoQvFqFGJCbysLOjUyXwNf/op8fd8+y10724h4MaOhUqVctY3awb77QdffWX3y5bZ2YWj4ziFIN+tMwARqQ50JbIFJiL7RaxQ9wK6A3OC+1OAW4Beqrolpk9acN0IaAIsSM7UXDgmTps2dp42rcBdFy+289KllhIqP95917JizJoF7drBK69Y+fbtMG8erF69a58JE+Ckk8yZf9y4+KmkRKBLl2zh6Jqj4ziFJcGtM4A+wKeqGt2XqguMDbbNJmJ7jqG54BNANeCzGJeNLsD0YBvubeCKZK4ceuDxRGkXGMtOnmwSpgAsWWJ7fhkZ8NFH2XI2Hqrwr39Bkybw+edw4YVw0UVw003m0K8KBx0E06dD9erWZ+tWuOCCbK3wgANyf363bvDOO7Yn6cLRcZyiEHgZjIopeybm/iXgpZiy6UDbXJ55SC7l7xAx6Ek2rjkmSu3aZu45ZUquTVRh0qRdyxcvNoHWvr0trebF6NEwdSrceqv1GTPGEgufdhrceSc89JA978Ybs/vce69plM8/n7dgBOja1c5ffWXCsXx5Tz/lOI4Ti2hhrD5KGFWqVNHNxeGG0auXSaFZs+JWjx4Np55qRjFhAG8wRVMEjjsO/vlPWLnStjBjUYVjj4XffrPXVKgQfxi3327a5QcfmOFNmzZw7rnw8sv5TyEryzTM3r3tfZ9/bgEDHMdxYhGRLapaJf+WpQ/XHAvCEUeY2WkugnbyZDvHys7Fi03p7NHDhNPo0fEfP24cjB8Pf/tb7oIRYNAgaNXKXDMuucSWVx96KLEplCtn2mOoOfqSquM4zq64cCwI7dqZupWLUc7MmXZeELGfUrU9x/r1TZvcf//cl1b/9S9bvb300ryHUbGiaYmrV8P339uy6377JT6Nrl1tjFOmuHB0HKd0IiI9RaTQMs6FY0EI8ziFKmIMM2bYOSocf//dUkfVq2da26mnmuaYmZmz79q1tsR52WWJ5VFs3dqi3Vx9NfTvn3/7KOG+48qVLhwdxym19AN+FpH7RaRZQTu7cCwIBxxg0iSOUc6OHTB3rl1HhWPo41g/iA7YowesWWOuF1HGjbMl1xNPTHw4l1wCTzxh+5kFoWVLqFHDrl04Oo5TGlHVCzCL2PlYhqdvg4QU1RLp78KxoLRrF1dznDfPNMSqVXMKx9DHsV4QcfCkk8ytY2SMq2zotN+pE0knLS3bG8WFo+M4pRVV3YC5f7yB+Vb2AaaIyLX59XU/x4JyxBG2Lrpli8VbDQj3G08+2fwIw+pYzbFGDfM1fP99GByJCjt2rCUYrlhxt8yCrl1NQLtwdEo6O3bsYPHixWzbti3VQymxVKpUifr161M+zHpeChCR07HA5Y2BV4AOqroyCII+G0uTmCsuHAtKu3a2/jl9eg41b8YMW9487TQTjr/8AocfbppjuXI5hVCfPrZXOGcONG1qzv3Tp8M99+y+afTubfkdw21UxympLF68mGrVqtGgQQOkoHsMDqrK6tWrWbx4MQ3DND6lg7OBR1R1XLRQVbeIyCX5dfZl1YISSpOYfccZM+CQQ0wgQvbS6pIlJhijKSV79bLze+/ZOQzndvzxyRlyPBo3NuHcoMHue6fjJINt27ax7777umAsJCLCvvvuWxo17zuA78MbEdlLRBoAqOoX+XV24VhQ6teHWrV22XecOdMEY6NGdh8Kx8WLs5dUo4848kgYMcLux461pB/RwAGO4ySOC8aiUUo/v7eArMh9ZlCWEC4cC4qIaY8R4bh9O/z8M7RoYZFvqlWD+fOtbsmSbGOcKH36mI/ikiUmHI891kK5OY5T8qhatWqqh+DsSrqq/hHeBNd5hFfJiQvHwtCunamKwTLE3Lnmt3j44SY7GzfOW3OE7FyLzz5r+R5355Kq4zhOGWCViPQKb0SkN/B7op1dOBaGTp0sxcbEiUC283+LII91o0YmHDdutPSP8TTHpk3h0EMtug1Y3FXHcUoP06ZNo1OnTrRq1Yo+ffqwdu1aAB577DGaN29Oq1at6NevHwBfffUVbdq0oU2bNrRt25aNGzemcuilhSuAv4vIbyKyCMsR+ZdEO7u1amE45hg7jxsHxx7LzJlmcHNokJO6USMLERf6OMbTHEVsafW++yw2atu4yVscxykQAwcWKudqnrRpA48+WuBuF110EY8//jhdu3Zl0KBB3HXXXTz66KMMHjyYX375hYoVK7Ju3ToAHnzwQZ588kk6d+7Mpk2bqBSbqdwpMKo6H+gkIlWxJBsF+sWRkOYoIlXCGHUicqiI9BKRsrtDVrOmhZkZZxbCM2aYYAyDhTdqZCuuYfqqeJojZC+tdu1qjvmO45QO1q9fz7p16+gaxGrs378/44Lvi1atWnH++efz6quvkh6YsXfu3Jkbb7yRxx57jHXr1u0s39MRkVNEZK6IzBORW+PU3xwkLJ4mIjNEJFNEaopIJRH5XkR+EJGZInJXpE9NEflMRH4OzvtE6m4L3jVXRE5OYHynAVcBN4jIIBEZlPDkVDXfA5gMVAbqAYuAEcBrifTdE47KlStrsXP11apVqqju2KGNG6uec0521SefqILqZZfZ+eef4z8iM1O1Tx/VkSOLf3iOU1aYNWtWqoegVapUyXG/bt06PfDAA3fez5s3T9u2bauqqhkZGTpmzBgdOHCgHnroobpjxw5VVZ0+fboOHjxY69Wrp7Nnz959gw+I9zkCmzV3uZCGhWZrhBm6/AA0z6P96cCY4FqAqsF1eWAC0Cm4vx+4Nbi+FbgvuG4evKMi0DB4d1oe73sGeDmQWXcAPwIv5tY+9kh0z1FUdQvwJ+BxVe0TDDTvTvn/qugmIusjvywGReoWisiPQfmkSPmdIrIk0qdHgnMoXrp0gc2b2fLtDyxYkO3fCNnuHMEPxVw1x3Ll4N134fTTkztUx3F2L9WrV2efffbh66+/BuCVV16ha9euZGVlsWjRIo477jjuv/9+1q1bx6ZNm5g/fz4tW7bklltuoX379syZMyfFM0iIDsA8VV2gZgn6BtA7j/bnAsMAAtm7KSgvHxxhcuHewNDgeihwRqT8DVXdrqq/APOCMeTG0ap6EbBWVe8CjgIOTHRyieruIiJHAecDYUKlPPuKSBrwJHAisBiYKCIjVTU2U/DXqtozl8ccp6rxrIseUdUHExx7cjj2WABmvzsL1SN2GuMAHHSQCb6ffrIV2ESybDiOU3LZsmUL9SPGBTfeeCNDhw7liiuuYMuWLTRq1Ij//ve/ZGZmcsEFF7B+/XpUlRtuuIEaNWrwj3/8g7Fjx5KWlkbz5s059dRTUzibHKRHlRPgOVV9LrgOVxJDFgMd4z0kCNl2CnBNpCwNW5U8BHhSVcN0DLVVdRmAqi4Tkf0j7/su5n25qB4AhFENtojIAcBqTONMiESF40DgNmCEqs4UkUbA2Hz67PxVASAi4a+KWOFYMqlbF5o0YcIXlvi4ZcvsqgoV4MAD4ddfc9caHccpPWRlZcUt/+6773Yp++abb3Ype/zxPMN8ppIMVc0tPEm8yAEapwxsSXW8qq7Z2VA1E2gjIjWAESLSQlVn5DGWgrwP4IPg2Q8AU4K2z+fRPgcJLauq6leq2ktV7wsMc35X1evy6RbvV0U8UXFUsCn7sYhEFidR4FMRmSwiA2L6XCMi00VkSHSzNkqQmmSSiEzKyMjIZ6iFpEsXhs1uTfPmyiGH5Kxq3NjO8SxVHcdxSgGLyblMWR9YmkvbfgRLqrGo6jrgS0yzBFghInUBgvPKgr4vkFNfqOo6VX0HOBhoqqoJG+Qkaq36uojsLSJVMM1vrojcnF+3OGWxUn4KcLCqtsYipL8Xqeusqu2AU4GrRSRIssTTWJT1NsAy4KF4L1fV51S1vaq2T5bl16/NT+WbjKM4/4QVu+RUDPcdXXN0HKeUMhFoIiINRaQCJgBHxjYSkepAV+D9SNl+gVaHiOwFdAfCjdaRQJjCvX+k30ign4hUFJGGQBMisVOjqGoWEdkQ7FOuL8jkEjXIaa6WF+sMYBRwEHBhPn3ylfKquiHclFXVUUB5EakV3C8Nzisx69gOwf0KVc0MJv88eW/IJpXXl1tYm/NqfbpLXSgcXXN0HKc0oqoZ2B7iJ1gKqDeDbbcrROSKSNM+wKequjlSVhcYKyLTMSH7map+GNQNBk4UkZ8xm5XBwftmAm9iCtpo4OpgaTY3PhWRM6WQgWMTVanKB36NZwBPqOoOEclrrRcivyqAJdivivOiDUSkDrBCVVVEOmDCenWgoZZT1Y3B9UnA3UGfuuFmLfah57VGnTRU4bVRNehc4XsazPwIuChHvWuOjuOUdgKlZlRM2TMx9y8BL8WUTQfihj5R1dXACbnU3Qvcm+DwbgSqABkisg1bzVRV3TuRzokKx2eBhZiPyTgRORjYkFcHVc0QkfBXRRowJPxVEdQ/A5wFXCkiGcBWoF8gKGtjG7ThGF9X1dHBo+8XkTbYEu1CChAOqDiZPh1mzhSeOnKG+WyoEl1bbdvWoua0apWK0TmO45RtVLVaUfpL4CxZ8I4i6YFavcdTpUoV3bx5c/4NC8Att8DDD8OywUOpddOfLXp406Y52mzaBB6s33GSy+zZs2nWrFmqh1Hiifc5isgWVa2SoiEViYidSg40JvlxbiRqkFNdRB4OrT9F5CFMXS2TZGXBsGFwyilQ60wLD8WoUbu0c8HoOGWHESNGICIlxYG/LHBz5PgH8AFwZ6KdEzXIGQJsBM4Jjg3AfwsyytLE11/DokVw3nlAgwYWHuejj1I9LMdxUsiwYcM45phjeOONN5L2jszMvOxPnCiqenrkOBFoAaxItH+iwrGxqt4RhAlaEITiaVSYAZcGPvrIHP17hZnCeva0fcf1BbIUdhynlLBp0ybGjx/Piy++uFM4ZmZmctNNN9GyZUtatWq109F/4sSJHH300bRu3ZoOHTqwceNGXnrpJa65ZmfwGHr27MmXX34JWCLlQYMG0bFjR7799lvuvvtujjzySFq0aMGAAQPCOKLMmzeP7t2707p1a9q1a8f8+fO58MILef/9nR4UnH/++YwcuYu3RVlhMSYgEyJRg5ytInKMqn4DICKdMQOaMsm4cXDkkVAlXFg+7TTLPfXZZ3DWWSkdm+OUZVKVseq9997jlFNO4dBDD6VmzZpMmTKFCRMm8MsvvzB16lTS09NZs2YNf/zxB3379mX48OEceeSRbNiwgb3yiS+5efNmWrRowd133w1A8+bNGTTIfNkvvPBCPvzwQ04//XTOP/98br31Vvr06cO2bdvIysrisssu45FHHqF3796sX7+e//3vfwwdOjSv15UaRORxsn3ry2G+8T8k2j9RzfEK4MkgGPhC4AlSZCWaajZvhsmTLe74To46CvbZBz78MNd+juOUXoYNG7YzcXG/fv0YNmwYn3/+OVdcccXO9FM1a9Zk7ty51K1blyOPPBKAvffeO9/0VGlpaZx55pk778eOHUvHjh1p2bIlY8aMYebMmWzcuJElS5bQp08fACpVqkTlypXp2rUr8+bNY+XKlQwbNowzzzyzxKTDKgYmYbFbJwPfAreo6gWJdk7oU1LVH4DWIrJ3cL9BRAYC0ws83BLOd99BRsbOuONGerpZ54waZdY65cqZFH3uORgwIKJiOo6TTAqRk7jIrF69mjFjxjBjxgxEhMzMTESEI444glj/c1XdpQwgPT09R3zWbdu27byuVKkSaUHC123btnHVVVcxadIkDjzwQO688062bdtGXl4HF154Ia+99hpvvPEGQ4YMKep0SxJvA9vCQAEikiYilYMMU/mSqOYI7IxoE/o33liwcZYOvv7aZN/RR8dU9OwJq1bBxInm83jxxXDjjfDOOykZp+M4u4e3336biy66iF9//ZWFCxeyaNEiGjZsSLt27XjmmWcIYzuvWbOGpk2bsnTpUiZOnAjAxo0bycjIoEGDBkybNm1nSqvvv48bFW2n0KxVqxabNm3i7bffBkwDrV+/Pu+99x4A27dvZ8sWkwF//vOfeTT41XB4NLde6ecLILpmvRfweaKdCyQcYyhUSJ6Szrhx0Lo1VK8eU3HKKSY1P/oIBg+Gt96y8lz+kzuOUzoYNmzYzuXMkDPPPJOlS5dy0EEH0apVK1q3bs3rr79OhQoVGD58ONdeey2tW7fmxBNPZNu2bXTu3JmGDRvSsmVLbrrpJtq1axf3XTVq1ODyyy+nZcuWnHHGGTuXZ8FyRj722GO0atWKo48+muXLlwNQu3ZtmjVrxsUXX5y8D2HPpFIkZyTBdeVEOxclCMBvqnpQoTrvZoorCMAff0CNGrZSGnf55thjYe5c+P136NcPli2z5VUXkI6TNDwIQN5s2bKFli1bMmXKFKrv8qs+m1IYBGA8cK2qTgnuj8DCnx6VSP88NUcR2SgiG+IcG4EDijz6EsbkybB1a8x+Y5TTTrOl1bZt4YUXoGNHM53bvn13DtNxHAeAzz//nKZNm3LttdfmKRhLKQOBt0TkaxH5GhhOJNlyfuRpkFPU2HSlja+/tnOuwvHCC00YPvAAVK4MHTrAjh3www927TiOsxvp3r07v/32W6qHkRJUdaKINAUOw7YB56jqjkT7F2XPscwxbhwcdhjsv38uDerVgzfegAODTF2hQJwwYbeMz3EcxzFE5GqgiqrOUNUfgaoiclWi/V04JkhmJnzzTYx/Y37Uqwd16/qeo+MkmcLaTjhGKf38LlfVdeGNqq4FLk+0swvHBJkxw6LD5bqkGg8R0x5dODpO0qhUqRKrV68urV/wSUdVWb16NZUqVSpwXxE5RUTmisg8Ebk1Tv3NIjItOGaISKaI1BSRA0VkrIjMFpGZInJ9pM/wSJ+FIjItKG8gIlsjdc/Evi+GctFExyKSBlRIdG5lJlRCUfnmGzsXSDiCCcf334e1ay2KjqoZ65x2GhxQ5myaHKfYqV+/PosXL2bVqlWpHkqJpVKlStSvX79AfQJh8yRwIha3dKKIjFTVWWEbVX0AeCBofzpwg6quEZGKwF9VdYqIVAMmi8hnqjpLVftG3vEQEA1aPV9V2yQ4xE+ANwMhqlikt48TnZ8LxwRZtMiCjR98cAE7duxo50mT4MQTLSjAgAFw+eUWQcdxnCJRvnx5GjZsmOphlEU6APNUdQGAiLwB9AZm5dL+XGAYgKouA5YF1xtFZDZQL9o30PrOAY4v5PhuAQYAV2IGOVOBuol29mXVBNmyxQxQ40R+ypv27e08YYK5dNxyi90PG2bZkB3HcfZc0iN5fCeJyIBIXT1gUeR+cVC2CyJSGTgF2CVkmIg0ANoCsZaLxwIrVPXnSFlDEZkqIl+JSJ7reKqaBXwHLADaAycAs/PqE8WFY4KEwrHAVK8OTZvavuOTT8KCBTBokAnGN98s9nE6juMUIxmq2j5yRJe74qkKuW38ng6MV9U10UIRqYoJzIGR0KQhOzXNgGXAQaraFgtf+noY7zvmmYeKyKBAG32CQICr6nGq+kTuU82JC8cE2bq1kMIRbN/xf/+Df/4TTj4Z7rwTmjWzvUfHcZySyWLgwMh9fWBpLm37kVPQISLlMcH4mqq+G1OXDvwJc9wHQFW3q+rq4HoyMB84NM675mBa4umqeoyqPg4UOEu0C8cE2bIF8km7ljsdOsDq1bBhAzz4oK3NXnYZfPstzJxZrON0HMfZTUwEmohIQxGpgAnAXTIpi0h1oCvwfqRMgBeB2ar6cJxnd8ec9hdH+uwXGAEhIo2AJtiSaSxnAsuBsSLyvIicQCFigSdVOCZg5ttNRNZHTHMHReoWisiPQfmkSHlNEflMRH4Ozvskcw4hhV5WhWyjnEsvhRZBIuoLL4Ty5eHFF4tlfI7jOLsTVc3AwrF9gu3lvamqM0XkChG5ItK0D/CpqkYDXHcGLgSOj3z/94jU76JpAl2A6SLyA5aO6orYZdpgXCMCi9emwJfADUBtEXlaRE5KdH6FDjye74NNwv9ExMwXODdq5isi3YCbVLVnnP4Lgfaq+ntM+f3AGlUdHAjcfVT1lrzGUhyBx7t0sbSNY8YUorMqvPIK9O6dM53HOefYA5csgYoVizQ+x3Gc4qYkBx6PIiI1gbOBvqqakPVrMjXHnWa+qvoHEJr5FpXewNDgeihwRjE8M1+KpDmKwEUX7Zrn6rLLbLn1zjvND9JxHMcpdlR1jao+m6hghOQKx0TNfI8SkR9E5GMRiWbiVOBTEZkcYz5cO/CRCX1l4kY6FZEBoflxmGy0KBRpzzE3une3PJCDB1uouT//GX76qZhf4jiO4xSUZArHRMx8pwAHq2pr4HHgvUhdZ1VtB5wKXC0iBYlqiqo+F5ofp6cXPdZBkTTH3ChXDj7+GKZMMc3ynXfMeOeLL4r5RY7jOE5BSKZwzNfMV1U3hJmaVXUUUF5EagX3S4PzSmAEtkwLsEJE6gIE55VJnMNOiuTKkR9t28Izz5jl6oEHmjbpbh6O4zgpI5nCMV8zXxGpEwaGFZEOwXhWi0iVIN4eIlIFOAmYEXQbCfQPrvsTMQ9OJklZVo3loINg/Hhbbr38cvjHP8yYx3Ecx9mtJC22qqpmiEho5psGDAnNfIP6Z4CzgCtFJAPYCvRTVRWR2sCIQG6mA6+r6ujg0YOxYLKXAr9hFkhJRTVJy6rx2Htv+OADuPJKuOceS5b8738XIm6d4ziOU1iSGng8WCodFVP2TOT6CSy8T2y/BUDrXJ65Got+sNvYsQOysnaTcATzGXn2WTvfd59J57vugtGj4a23oEEDuPfe3TQYx3Gcsodn5UiALVvsvNuEI5ixzlNP2fn+++Gxx2DbNvOH3L4devSAzp1344Acx3HKDi4cEyAUjknfc4xFBJ54AmrVgsWLLWhAp07QvDn89a8Wfs6XWx3HcYodF44JkBLNMUTEllSj3HMPXHIJDB8O/fqlYFCO4zilGw88ngBbt9o5JcIxHhddBK1bw6232lKr4ziOU6y45pgAKVtWzY20NHjoIXP5uOEGyxe5bJn5SF51lS+1Oo7jFBEXjgmQ0mXV3DjhBDj9dAseACYwMzNNMF51VWrH5jiOU8LxZdUE2OOWVUPeeAN+/BFWrcq2YL3hBpg8OdUjcxzHKdG4cEyAPVJzBBtQixZmzZqWBi+/DLVrw9lnw7p1qR6d4zhOicWFYwLscXuOubHvvvDmm7BokWX4yMxM9YgcxynFJJDQ/uZIMuMZIpIZJKw/UETGishsEZkpItdH+twpIkviJUEWkduCd80VkZOTOTcXjgmwx2qO8ejUCR5+GN5/3/wi3ZrVcZwkECS0fxLLnNQcOFdEmkfbqOoDqtpGVdsAtwFfqeoaIAP4q6o2AzphmZeifR8J+wWR1gjq+wGHA6cATwVjSAouHBNgj91zzI1rr4VHH4V337V9yA0bUj0ix3FKHwVNaH8uMAwsF6+qTgmuNwKziZ/vN0pv4A1V3a6qvwDzyM7WVOy4cEyAErOsGuX66+GVV+Drr+G44yzCjuM4TvGRaEJ7RKQypu29E6euAdAWmBApvkZEpovIEBHZp6DvKw5cOCbAli1m71K+fKpHUkAuuMCWV3/6yXJGehJlx3EKRrqITIocAyJ1iSS0DzkdGB8sqWY/QKQqJjAHqmq4xPU00BhoAywDHirE+4qM+zkmQJiuqkT61vfoAZMmwZ/+BCedBDfdZJOZOxeWLLFIO926QZcuZvXqOI6TTYaqts+lLt+E9hH6ESyphohIeUwwvqaq74blqroi0uZ54MNCvK/IuOaYAFu3lqD9xngcdhhMmGAGOvffb7Fav/3WcnG9+CKceSbUqWOuII7jOImRb0J7ABGpDnQlkpg+SHL/IjBbVR+OaV83ctuHnInu+4lIRRFpCDQBvi/G+eTAhWMCbNlSwvYb41G1Krz+Ovz2G2zeDL/8Av/7H6xdC+PHw7HHwmWXwbhxqR6p4zglAFXNAMKE9rOBN8OE9mFS+4A+wKequjlS1hm4EDg+jsvG/SLyo4hMB44DbgjeNxN4E5gFjAauVtWk+auJatKWbPcYqlSpops3b86/YS6cdRbMng0zZxbjoPY01q2Do46ClStNyzzkkFSPyHGcFCMiW1S1SqrHkQpcc0yAEr+smgg1asCHH9rG6mmnwfLlqR6R4zhOynDhmAClYlk1ERo3hhEj4NdfoUkT25vcuNGWYd9915ZdP/gg1aN0HMdJOr6smgAdO8I++8Do0cU4qD2Zn36C22+Ht9+GmjXt18G2bVCunB3vvAO9eqV6lI7jJBlfVk0SCcTd6yYi6yMbsoNi6tNEZKqIfBgpyzXuXrIIXTnKDIceCm+9Bd99Z6mxBgyAMWNsP7JdOwts/vHH2e03boQ//kjdeB3HcYqZpPk5RuLunYj5p0wUkZGqOium6deq2jOXx1yPWUHtHVP+iKo+WKwDzoMysecYj44dLZB5lNGjLclynz5w6qkwfTosWACdO8PYsSUwUoLjOM6uJFNzLGjcvRyISH3gNOCFJI0vYcrMnmMi7LMPfPopHH205ZJs1w6uvNLcQQYNyr+/4zhOCSCZEXLixcHrGKfdUSLyAxbp4KbAlwXgUeBvQLU4fa4RkYuASVhk97WxDYIwRwMAKlSoUNg5AGVwWTU/9t3XllmjZGbC4MEWbefkpGaScRzHSTrJ1BwTiYM3BThYVVsDjwPvAYhIT2ClqsZLaZ9b3L2cL1J9TlXbq2r79PSi/QYos8uqBeHRRy3x8oUXwpQp8MYbcPXVZthTBGMox3GcVJBMzTHfOHiRQLOo6igReUpEamHRE3oFxjaVgL1F5FVVvSCPuHtJISPDbE18WTUf9trL9ifbt4cjjrCyKlVMML7zDgwbZsHPAZYuhfXroVmz1I3XcRwnD5KpOeYbd09E6gQx9hCRDsF4VqvqbapaX1UbBP3GqOoFQbvc4u4lhRKXyzGVNGtmfpCPPGLBztetg88/N2vWjh3NyrVJE6hXD5o3t4g8w4dbjFfHcZw9iKRpjqqaISJh3L00YEgYdy+ofwY4C7hSRDKArUA/zd/x8n4RaYMt0S4E/pKkKQDZuRxdOCbI8cfbEXLCCWbRetVV8NVX0KmTGfCkpcETT0C/flC7tmUFOfpo27Ns0yZVo3ccxwE8CEC+LFwIDRvCf/8Lf/5zsQ7LycqCUaPgtdcsCPpvv1l53762h1mnTkqH5zhlHQ8C4ORKqDn6nmMSKFcOeva0/chff4VFiyxk3XvvQdOm8MwzUAZ+vDmOs+fhwjEffFl1N1K/vvlKTp9uRj1XXmm5JjdsyL+v4zhOMeLCMR/cICcFHHqoGfI88giMHAkdOsCsWTBtGtx7r0Xm+de/YMWKfB/lOI5TGFw45oMvq6YIERg40IINrFsHhx9uriD/938wb575Tx54oBn0TJ2a6tE6jlPKcOGYD76smmK6dIHJk+Fvf4MhQ2DZMvj5Z5gzx4IMfPKJhbA791wTmtu3W1i7YcPgllvgpJPMGvaaa1I9E8cpdSSQXOLmSJKIGSKSKSI1ReRAERkrIrNFZKaIXB/p84CIzBGR6SIyQkRqBOUNRGRr5HnPJHVubq2aN6+9BhdcAHPn2mqfs4exfj088IAtwW7fbmWZmXYuX96i9lSqBN9+CxMm2BKt4zgJkZe1apBc4iciySWAc+Mklwjbnw7coKrHB/7qdVV1iohUAyYDZ6jqLBE5CfNtzxCR+wBU9RYRaQB8qKotinue8UhmhJxSge857uFUrw733GOa4eOP23Ls4Yfb0bQpVKhgQQiaNLFl2vHjrY3jOEVlZ3IJABEJk0vEFY7AucAwAFVdhoX/RFU3ishsLB73LFX9NNLnO8wffrfjwjEffM+xhFCnjhnrxKNaNTPgufRSW24977xd28ybB/Pne9B0x8lJuohMitw/p6rPBdeJJpdARCoDpwC77G8EGmFbYEKcrpcAwyP3DUVkKrAB+D9V/TrBeRQY33PMB99zLCX8+c+2N3nLLdn/qCE7dsDpp5sV7KhRKRme4+yhZIQJHILjuUhdIsklQk4HxqvqmmihiFQF3gEGRmNtB3W3AxnAa0HRMuAgVW0L3Ai8LiKxuX6LDReO+RAuq1aqlNpxOEWkXDmLurN4Mfz73znrnn3WDHzq1LEN5l9+SckQHaeEkW9yiQj9CJZUQ0SkPCYYX1PVd2Pq+gM9gfPDkKKqul1VVwfXk4H5QNIsQVw45kOY6Ni3qUoBxx5rKbXuvRdGjLCytWvhjjssHuzXX1tEnjPPzP5V5DhObuSbXAJARKoDXYH3I2UCvAjMVtWHY9qfAtwC9FLVLZHy/QIjIESkEdAEWFDsswrwPcd88ETHpYxnn4WffoLzz4cvv7S8k2vXwsMPQ+PG8MortsR68slQo4ZpmuXKWeSe00/3X0mOE5Bgcgmw7EmfqmrUZaAzcCHwo4hMC8r+rqqjgCeAisBnQdKm71T1CqALcHeQqCITuCJ2mbY4cVeOfLj4Yvjii+yY2E4pYMUKyw6yebMFGLjoInjhhez6Bx6Ahx4y/8j69c1QZ+5cOPFEuPNO0y6XLrVfTmecYRazYC4k999vxj/HHmsBC44+OgUTdJzioSwHHnfhmA/9+lnUsjlzindMToqZPdvySWZmWlCBvDKA7NgBTz9ty6/r1uWsq14drrsOevWC66+37CLdu9t/mt9/txRczzwDhx2WxMk4TnJw4VjKKYpw7NXLkkV4hLJSyOzZsGkTHHlkYu1//90i8uy7LxxwgGmODzwA7wa2BNWrw1NPWbSeLVvg+edtfzMtzcLgNW+evLk4ThJw4VjKKYpw7N7dbDPGjy/mQTmlh5kzzQWkXz+L9xplzhw47jjLXfnFFxaxJzeWL4d//hMaNICbb07qkB0nEcqycHSDnHzYsgWqlMn/Gk7ChBF54tG0qRn+HHecHY88Aj16QM2a2W22bzc3k3vuMU0WoGpVS9kVsmCBLem2a5ekSTiOE8VdOfJh61aPjuMUkcMOg6++gr33NleS/faDzp0tKHrTprDPPnDrrXDCCaZp9uxp4fA+/NA0zsceM+HbqZMHKXCc3YQvq+bDYYdZpqQ33ijmQTllj6wsmDgRPvrI9i4BDjrIlmJ79jRfSzAr2q5dbU/0iCPM/7JHD1t2nTULPv7YDH0Afv0VVq2C9u1TMiWndFOWl1WTKhwDZ87/YD4wL6jq4Jj6bphjaBiS5F1VvTtSnwZMApaoas+grCYWa68BsBA4R1XX5jWOogjHAw80C/4hQwrV3XEKx/LlZk27apUtxV52GaxebULz11/NXWTUKPj0U3Mtueoqa1ehQsHeM3OmBWUvaD+nTFCWhWPSllUDwfYkcCrQHDhXROKZ632tqm2C4+6YuuuB2TFltwJfqGoT4IvgPmls3epBAJwUUKeO5bGcPx8uv9yCD9SqBZ9/bnXXX29a5KBBcMMNZiXbrRssWZL4Ox55xAyEjj/efD8dx9lJMg1yCprOJAciUh84DbgXCzIb0hvoFlwPBb7EQg0lhTB8nOPsdqJGOyF165rp9KxZlgg6Lc3Kjz7aIlY0bQpt2tge5SGHWH1WFlSsCH/6k7mgADz5JNx4oz1j4kRblh0xwpdnHScgmcIx0XQmR4nID1jA2ptUdWZQ/ijwN6BaTPvaQS4wVHWZiOwf7+UiMgAYAFChkEtGWVmuOTp7ILVr2xHlrLNMIP7nP7ZU+uabFhYvyg03QN++JkD/8Q/o3Rveesvan3GGRfV58cX4Kb0cp4yRTOGYSDqTKcDBqrpJRHoA72GBbHsCK1V1crAvWWCC1CrPge05FuYZ27bZ2YWjUyJo1syi8YDtQ27caOdy5WDZMovy8+KL8Nprlp5r+HAoX940zYkTTcCef75ZzN55p/WLsnq1RcM47LBd/Tn/+1/47DNo2NBi1B59tAlhxymhJFM45pvOJJq/S1VHichTIlILC0rbKxCYlYC9ReRVVb0AWCEidQOtsS6wMlkTCBMz+LKqU+IQMdeRkGrVbI/xrrssGMGpp9pSa8h++5lwu/JKC0QwZ44Jy5kz7ZgyJTuVV/XqppmedJIJ33vvNU10//1NgGZmmtB96SXXQp0SSzL9HPNNZyIidYLUJYhIh2A8q1X1NlWtr6oNgn5jAsFI8Iz+wXV/ImlQihtPdOyUOvbeG/r0iZ+gtEIFC8D+wAPw9tu2BHvPPTB9uu1F3ncffPABHHywuZY88QT8/e8mGC+80IyBtm2zrCdHH21a6P33mwB1nBJG0jTHBNOZnAVcGaQg2Qr00/x9SwYDb4rIpcBvwNnJmoMLR6fMIQI33QSnnQZ//GFLqLGCtGtX0wivvdbur7jCDHzCZdgmTcyPs39/uOUW+P57W2KtXBkyMkx4zp2b7ZrSo4f5S9WoUbxzmTXLDJI86LtTCDwIQB5Mm2YBAEaMMHsFx3ECMjPN17JcOdMe4+W5zMqyuqeessAGWVlWftBBJrCqVYOxY81wKC0NOna0pdqTT7br2GeuX2/LteGv1eXLYdgwMyrq29fcW0IWLYJWrUyTHToUzjknOZ9DKacs+zmiqqX+qFy5shaG8eNVQXX06EJ1dxwnJCtLdds21a1bc5bv2KH6zTeqf/+76pFHqorYH91pp6n+9pu12bxZ9ZZbVNPTrW6//VRbtlQtV87ua9e2fh99ZO0zM1W7dVOtUkW1Y0drc9ddNganQACbNY/vVuAUYC4wD7g1Tv3NwLTgmIElKa6J2aOMxfzYZwLXR/rUBD4Dfg7O+0TqbgveNRc4Oa+xFfVIueDaHUdhheNnn9knNG5cobo7jlNQfv9d9cEHVStXVq1aVfX221UbNLA/xP79Ve+5R3XAANUePUygzpplwrNNG9Xq1VV/+kn1/vut/YsvmkC+6CK779lTdfbsVM+wRJGXcMS2y+YDjYAKwA9A8zzan47ZjwDUBdoF19WAn8K+wP2hoMWCvNwXXDcP3lERaBi8Oy239xX18KwceeB7jo6zm9l3X/jrX+HMM+EvfzFL2KZNLXB7ly659xsxwuLQnnoq/PabBTy4+GJbmn3pJXNXGTTIfEH79zcjooYNs/urWji+sWPNh7R+fahXz6x4a9WygAxhwAUnpKCBXs4FhoH5qAOhv/pGEZmN+cbPIvdAL72BN1R1O/CLiMwLxvBtcU8MPGVVnrgrh+OkiAYNYPRomDTJ9g6jbie5tR8+3PYra9eG557L3rMUsQAIF1wAgweb8dBLL1kKsYsuMgvee++1cH3p6WY0FEvVqiZQb7jB9j0BNmywIPBpaZZZpWZNaNnSnlEUFi609GRt2hTtOcVDuohMitw/p+ZDDokHekFEKmNLsNfEqWsAtAUmBEW5BXqpB3wX8756BZpNAXDhmAeuOTpOChGBI49MvH337uarWbeuaaCx7LcfPPSQCbghQ+Dll+HPf7a6Ro0sQMKFF9qv4sWLzTXl99/t+Pxzs7x99VULkDBmjBn6hPk3Qw46yDTeSy/dNYpRIvz8s6UzW7/efhwcd1zBn1G8ZKhqbjEFEwn0EnI6MF5V1+R4gEhV4B1goEb83ovhfUXGrVXz4MknLa3eihXm3+w4TilCFf73P8t80rNn/hrf++/bF8LixeYT2q8fDBhgmufatWYh+9JLJkjT001Ap6VZ27/+1fpGeeEF01Ivvtg046VLTTBu2mRLuUuWWKLseAmuX33V8nzWqmXRilq0sAAORdVaY8jLWlVEjgLuVNWTg/vbAFT133HajgDeUtXXI2XlgQ+BT1T14Uj5XKCbZgd6+VJVD4t9voh8Erw/KcuqKTeW2R1HYQ1yHnjA9vE3bixUd8dxShsbNqi+847qypW5t5kzx4yFBgxQvfRS1c6d7Yvk5Zez2/z731YGqgcdpPrMM6otWpgR0sSJqosWWfl++5mRUZTQ4Ojww1XbtbM2oHrddcU+XfI2yEkHFmDGMaFBzuFx2lUH1gBVImUCvAw8Gqf9A+Q0yLk/uD6cnAY5C0iiQU7KBdfuOAorHO+6yz6hjIxCdXccxzGL2RNOMFeUjz82a1xQPe88uz/ySLuvUEH188+z+82Zo1qrluree6teeKHqu++q3nijte3bV3X79uy2Awda+dNPZ5fNn2+WuqtWFXroeQlHq6YHZmk6H7g9KLsCuCLS5s+YIU203zHYkuh0sl09egR1+2LpCH8OzjUj/W4P3jUXODWvsRX18GXVPLj1VgtHuX17EgblOE7ZYcMGy7c5c6ZFHjrnHAsAn55u+uPHH1tQhGOPzdlv5kx48EEYORLWBNt1114Ljz6aMzB8ZqZlWRk92uLefvedZWhJT7dQgKeeWqhhl+UgAC4c8+C66+CVV3bN/OM4jlNgli+HE04w69uXX862ek2EjAwYN86MhXr0iB+RaMMG27OcMcPq+/e32Lj1Cm/Q6cKxlFNY4fjCC/Dtt2bE5jiOU2RU4wu24uLXXy3Y+yWXmN9nEXHhWMoprHB0HMcpy5Rl4ZjMlFWO4ziOUyJx4eg4juM4MbhwdBzHcZwYXDg6juM4TgwuHB3HcRwnBheOjuM4jhODC0fHcRzHicGFo+M4juPEUCaCAIhIFrC1AF3SgTgZT0s9ZXHeZXHOUDbnXRbnDEWb916qWiaVqDIhHAuKiEzS3BN8llrK4rzL4pyhbM67LM4Zyu68i0qZ/EXgOI7jOHnhwtFxHMdxYnDhGJ/nUj2AFFEW510W5wxlc95lcc5QduddJHzP0XEcx3FicM3RcRzHcWJw4eg4juM4MbhwjEFEThGRuSIyT0RuTfV4koGIHCgiY0VktojMFJHrg/KaIvKZiPwcnPdJ9ViLGxFJE5GpIvJhcF8W5lxDRN4WkTnBv/lRpX3eInJD8H97hogME5FKpXHOIjJERFaKyIxIWa7zFJHbgu+2uSJycmpGXTJw4RhBRNKAJ4FTgebAuSLSPLWjSgoZwF9VtRnQCbg6mOetwBeq2gT4IrgvbVwPzI7cl4U5/wcYrapNgdbY/EvtvEWkHnAd0F5VWwBpQD9K55xfAk6JKYs7z+BvvB9weNDnqeA7z4mDC8ecdADmqeoCVf0DeAPoneIxFTuqukxVpwTXG7Evy3rYXIcGzYYCZ6RkgElCROoDpwEvRIpL+5z3BroALwKo6h+quo5SPm8sKsxeIpIOVAaWUgrnrKrjgDUxxbnNszfwhqpuV9VfgHnYd54TBxeOOakHLIrcLw7KSi0i0gBoC0wAaqvqMjABCuyfwqElg0eBvwFZkbLSPudGwCrgv8Fy8gsiUoVSPG9VXQI8CPwGLAPWq+qnlOI5x5DbPMvc91tRcOGYE4lTVmp9XUSkKvAOMFBVN6R6PMlERHoCK1V1cqrHsptJB9oBT6tqW2AzpWM5MVeCPbbeQEPgAKCKiFyQ2lHtEZSp77ei4sIxJ4uBAyP39bHlmFKHiJTHBONrqvpuULxCROoG9XWBlakaXxLoDPQSkYXYcvnxIvIqpXvOYP+nF6vqhOD+bUxYluZ5dwd+UdVVqroDeBc4mtI95yi5zbPMfL8VBy4cczIRaCIiDUWkArZ5PTLFYyp2RESwPajZqvpwpGok0D+47g+8v7vHlixU9TZVra+qDbB/1zGqegGleM4AqrocWCQihwVFJwCzKN3z/g3oJCKVg//rJ2D76qV5zlFym+dIoJ+IVBSRhkAT4PsUjK9E4BFyYhCRHtjeVBowRFXvTe2Iih8ROQb4GviR7P23v2P7jm8CB2FfMGerauxmf4lHRLoBN6lqTxHZl1I+ZxFpgxkhVQAWABdjP4xL7bxF5C6gL2aZPRW4DKhKKZuziAwDugG1gBXAHcB75DJPEbkduAT7XAaq6se7f9QlAxeOjuM4jhODL6s6juM4TgwuHB3HcRwnBheOjuM4jhODC0fHcRzHicGFo+M4juPE4MLRcYoBEckUkWmRo9ii0IhIg2jWBcdxkk96qgfgOKWEraraJtWDcByneHDN0XGSiIgsFJH7ROT74DgkKD9YRL4QkenB+aCgvLaIjBCRH4Lj6OBRaSLyfJCj8FMR2Stlk3KcMoALR8cpHvaKWVbtG6nboKodgCew6EsE1y+raivgNeCxoPwx4CtVbY3FQJ0ZlDcBnlTVw4F1wJlJnY3jlHE8Qo7jFAMisklVq8YpXwgcr6oLgmDvy1V1XxH5HairqjuC8mWqWktEVgH1VXV75BkNgM+C5LWIyC1AeVW9ZzdMzXHKJK45Ok7y0Vyuc2sTj+2R60zcXsBxkooLR8dJPn0j52+D6/9h2UEAzge+Ca6/AK4EEJE0Edl7dw3ScZxs/Nen4xQPe4nItMj9aFUN3TkqisgE7MfouUHZdcAQEbkZWIVlygC4HnhORC7FNMQrsWz2juPsRnzP0XGSSLDn2F5Vf0/1WBzHSRxfVnUcx3GcGFxzdBzHcZwYXHN0HMdxnBhcODqO4zhODC4cHcdxHCcGF46O4ziOE4MLR8dxHMeJ4f8BjRbq2Za+rmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize Loss/Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "history_df = pd.DataFrame(fit_model_reduced_input.history,\n",
    "                          index=range(1, len(fit_model_reduced_input.history[\"loss\"]) + 1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "loss = ax.plot(history_df[\"loss\"], color=\"red\", label=\"Loss\")\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "acc = ax2.plot(history_df[\"accuracy\"], color=\"blue\", label=\"Accuracy\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "\n",
    "curves = loss + acc\n",
    "labs = [l.get_label() for l in curves]\n",
    "ax.legend(curves, labs, loc=\"center right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27d925aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export and save model to HDF5 file\n",
    "nn_reduced_input.save(\"AlphabetSoupCharity_Optimization.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51222e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
